{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 신경망 기본 아키텍쳐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝 라이브러리를 활용하지 않고, 파이썬 코드만으로 단순한 신경망을 구현해보겠다.\n",
    "\n",
    "기본 신경망은 다음 요소로 구성된다.\n",
    "\n",
    "- 입력 레이어 한 개(x)\n",
    "- 은닉 레이어 다수\n",
    "- 출력 레이어 한 개(y햇)\n",
    "- 각 레이어 간 가중치(w)와 편향(b)\n",
    "- 각 은닉 레이어의 활성화 함수(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 파이썬만으로 신경망 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00949661]\n",
      " [0.96872454]\n",
      " [0.96845817]\n",
      " [0.03819881]]\n"
     ]
    }
   ],
   "source": [
    "# 활성함수를 먼저 만들어주자.\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1.0 - x)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    # layer 2개를 가진 신경망에 대한 값 선언\n",
    "    def __init__(self, x, y):\n",
    "        self.input = x\n",
    "        self.weight1 = np.random.rand(self.input.shape[1], 4)\n",
    "        self.weight2 = np.random.rand(4, 1)\n",
    "        self.y = y\n",
    "        self.output = np.zeros(self.y.shape)\n",
    "        \n",
    "    # 1.3.3.1 훈련을 위한 순전파 과정\n",
    "    def feedforward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weight1)) #인풋과 w1을 받아서 활성함수를 거쳐, layer1 결과물이 나온다.\n",
    "        self.output = sigmoid(np.dot(self.layer1, self.weight2)) # layer1의 결과물과 w2를 받아서 활성함수를 거쳐, output이 나온다.\n",
    "        \n",
    "    # 1.3.3.2 평가를 위한 손실함수\n",
    "    # SSE\n",
    "    \n",
    "    # 1.3.3.3 오차 개선을 위한 역전파 과정\n",
    "    def backprop(self):\n",
    "        # weight2와 weight1에 따른 손실 함수의 미분을 찾기 위해 연쇄 법칙을 활용\n",
    "        d_weight2 = np.dot(self.layer1.T, (2*(self.y - self.output) * sigmoid_derivative(self.output)))\n",
    "        d_weight1 = np.dot(self.input.T,(np.dot(2*(self.y - self.output) * sigmoid_derivative(self.output),\n",
    "                                                self.weight2.T) * sigmoid_derivative(self.layer1)))\n",
    "        \n",
    "        # 손실 함수의 미분 값을 사용해 가중치를 갱신한다.\n",
    "        self.weight1 += d_weight1\n",
    "        self.weight2 += d_weight2\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    X = np.array([[0,0,1], [0,1,1], [1,0,1], [1,1,1]])\n",
    "    y = np.array([[0], [1], [1], [0]])\n",
    "    nn = NeuralNetwork(X, y)\n",
    "    \n",
    "for i in range(1500):\n",
    "    nn.feedforward()\n",
    "    nn.backprop()\n",
    "\n",
    "print(nn.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.2 케라스로 신경망 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 파이썬으로 간단한 신경망을 만들었다면, 이제 케라스로 똑같이 만들어보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스를 통한 신경망 구성 요소는 다음과 같다.\n",
    "\n",
    "- 레이어 : 기본 빌딩 블록으로 레이어를 쌓아 모델을 생성\n",
    "- 옵티마이저 : 훈련을 시키는 알고리즘(SGD, ADAM 등)\n",
    "- 손실함수 : 오차 지표(MSE, CCE, BCE 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이어를 나란히 연결하기 위해 Sequential 을 먼저 선언해준다.\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense # 완전연결 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer1\n",
    "model.add(Dense(units=4, activation='sigmoid', input_dim=3)) # input_dim은 데이터셋의 변수가 몇 개인지 지정하는 것이다.\n",
    "# 출력 레이어\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 21\n",
      "Trainable params: 21\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary()) #param은 모델이 훈련해야 할 가중치와 편향 개수다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers # 옵티마이저를 정의하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=1) # SGD로 간다. lr은 learning rate.\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd) # 손실함수는 MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전과 동일한 데이터셋을 만들어서 돌려보자.\n",
    "np.random.seed(9)\n",
    "X = np.array([[0,0,1], [0,1,1], [1,0,1], [1,1,1]])\n",
    "y = np.array([[0], [1], [1], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07159124]\n",
      " [0.94394034]\n",
      " [0.9117078 ]\n",
      " [0.08230858]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=1500, verbose=False)\n",
    "print(model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전혀 수학적 코드 없이도 케라스 만으로 신경망을 돌릴 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
