{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. 카운트 기반의 단어 표현(Count-based word Representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적으로 크게 두 가지 표현 방법이 있습니다.\n",
    "\n",
    " - 국소 표현(Local Representation) = 이산 표현(Discrete Repre-)\n",
    " - 분산 표현(Distributed Representation) = 연속 표현(Continuous Repre-)\n",
    " \n",
    "국소 표현은 단순히 강아지, 귀여운, 사랑스러운 을 1, 2, 3 으로 맵핑하는 것이며,\n",
    "\n",
    "분산 표현은 강아지와 자주 등장하는 귀여운, 사랑스러운을 같이 엮는 것입니다.\n",
    "\n",
    "국소 표현은 주로 One-Hot Vector, N-gram, BoW 등이 있으며,\n",
    "분산 표현은 Word2Vec, LSA, Glove 등이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Bag of Words(BoW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Words는 단어들의 순서는 전혀 고려하지 않고, 출현 빈도만 집중하는 수치화 표현 방법입니다.\n",
    "\n",
    "BoW 만드는 과정\n",
    "1. 우선, 각 단어에 고유한 정수 인덱스를 부여합니다.\n",
    "2. 각 인덱스의 위치에 단어 토큰의 등장 횟수를 기록한 벡터를 만듭니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. Bag of Words 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "\n",
    "# 정규 표현식을 통해 온점 제거\n",
    "token = re.sub(\"(\\.)\",\"\",\"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\")\n",
    "\n",
    "# Okt 형태소 분석기를 통해 토큰화 작업 수행 후, token에 할당\n",
    "token = okt.morphs(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}\n"
     ]
    }
   ],
   "source": [
    "word2index = {}\n",
    "bow = []\n",
    "for voca in token:\n",
    "    if voca not in word2index.keys():\n",
    "        word2index[voca] = len(word2index)\n",
    "        # token을 읽으면서, word2index 에 없는 단어는 새로 추가하고, 이미 있는 단어는 넘깁니다.\n",
    "        \n",
    "        bow.insert(len(word2index)-1, 1)\n",
    "        # bow 전체에 기본값 1을 넣어줍니다.\n",
    "        \n",
    "    else:\n",
    "        index = word2index.get(voca)\n",
    "        # 재등장하는 단어의 인덱스를 받아옵니다.\n",
    "        \n",
    "        bow[index] = bow[index] +1\n",
    "        # 재등장한 단어는 인덱스의 위치에 1을 더해줍니다.( 단어를 세어줍니다.)\n",
    "        \n",
    "print(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 1, 2, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3. CountVectorizer 클래스로 BoW 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷 런에서 단어의 빈도를 Count하여 Vector로 만드는 클래스가 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['you know I want your love. Because I love you.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 2 1 2 1]]\n"
     ]
    }
   ],
   "source": [
    "print(vector.fit_transform(corpus).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'you': 4, 'know': 1, 'want': 3, 'your': 5, 'love': 2, 'because': 0}\n"
     ]
    }
   ],
   "source": [
    "print(vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4. 불용어를 제거한 BoW 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.4.1. 사용자가 직접 정의한 불용어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1]]\n",
      "{'family': 1, 'important': 2, 'thing': 4, 'it': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "text=[\"Family is not an important thing. It's everything.\"]\n",
    "vect = CountVectorizer(stop_words=[\"the\", \"a\", \"an\", \"is\", \"not\"]) # 여기 파일 끌어와도 됨\n",
    "print(vect.fit_transform(text).toarray()) \n",
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.4.2. CountVectorizer에서 제공하는 자체 불용어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]]\n",
      "{'family': 0, 'important': 1, 'thing': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text=[\"Family is not an important thing. It's everything.\"]\n",
    "vect = CountVectorizer(stop_words=\"english\")\n",
    "print(vect.fit_transform(text).toarray())\n",
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.4.3. NLTK에서 지원하는 불용어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thinp\\anaconda3\\envs\\Wyatt37\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1]]\n",
      "{'family': 1, 'important': 2, 'thing': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "text=[\"Family is not an important thing. It's everything.\"]\n",
    "sw = stopwords.words(\"english\")\n",
    "vect = CountVectorizer(stop_words =sw)\n",
    "print(vect.fit_transform(text).toarray()) \n",
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. 문서 단어 행렬(Document-Term Matrix, DTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "간단하게 말하면 DTM은 BoW를 행렬로 만들어 놓은 것입니다.\n",
    "BoW가 하나의 벡터라고 한다면 그것을 쌓아 매트릭스로 만든 것이지요.\n",
    "\n",
    "다만 문제점이라고 하면\n",
    "\n",
    "- 희소 표현: 매트릭스의 대부분의 값이 0이 되어서 리소스 낭비가 극심함.\n",
    "- 단순 빈도 수 기반 접근: the 같은 애들이 많다고 연관성 있는 거 아님."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. TF-IDF(Term Frequency-Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이놈은 말입니다. 단어의 빈도와 역 문석 빈도를 사용하여 DTM내의 각 단어들마다 중요도를 가중치로 줍니다.\n",
    "\n",
    "그래서 DTM을 만들고, TF-IDF로 가중치를 부여합니다. 여기서\n",
    "\n",
    " - d: 문서\n",
    " - t: 단어\n",
    " - n: 문서의 총 개수\n",
    " \n",
    "일 때, tf, df, idf로 정의할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.1.1 tf(d,t): 특정 문서 d에서의 특정 단어 t의 등장 횟수."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그냥 이것은 DTM을 말하는 겁니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.1.2 df(t): 특정 단어 t가 등장한 문서의 수."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 문서, 또는 문서들에서 특정 단어 t가 몇 번 등장했는지 중요하지 않습니다. 오로지 등장 했냐 안했냐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.1.3. idf(d, t): df(t)에 반비례하는 수."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idf(d, t) = log(n/1+df(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDF라는 이름을 보고 DF의 역수가 아닐까 생각했다면, IDF는 DF의 역수를 취하고 싶은 것이 맞습니다. 그런데 log와 분모에 1을 더해주는 식으로 좀 이상합니다. IDF를 DF의 역수로 사용하면 문서의 수n가 커질수록 기하급수적으로 커져서 log를 취합니다. 또한 희귀 단어늗에 log를 취하지 않으면 어마어마한 가중치가 부여됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2. 파이썬으로 TF-IDF 직접 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4개의 문서를 docs에 저장합니다.\n",
    "\n",
    "docs = [\n",
    "  '먹고 싶은 사과',\n",
    "  '먹고 싶은 바나나',\n",
    "  '길고 노란 바나나 바나나',\n",
    "  '저는 과일이 좋아요'\n",
    "] \n",
    "vocab = list(set(w for doc in docs for w in doc.split()))\n",
    "vocab.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['과일이', '길고', '노란', '먹고', '바나나', '사과', '싶은', '저는', '좋아요']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF, IDF, TF-IDF 값을 구하는 함수를 구현합니다.\n",
    "\n",
    "N = len(docs) # 총 문서의 수\n",
    "\n",
    "def tf(t, d):\n",
    "    return d.count(t) # 문서 d에서 단어 t가 몇 번 등장하느냐.\n",
    "\n",
    "def idf(t): #df의 역수이니 df를 먼저 정의하고 idf를 구해줍니다.\n",
    "    df = 0 # 빈 df 만들고.\n",
    "    for doc in docs: # 문서의 등장 여부를 따지려는 for 문.\n",
    "        df += t in doc # docs에 t가 존재하면 더해줍니다.\n",
    "    return log(N/(df + 1)) # idf 식에 맞춰서 df의 역수를 취하며 +1을 취하고 log를 취해줍니다.\n",
    "\n",
    "def tfidf(t, d):\n",
    "    return tf(t,d)*idf(t) # 두개를 곱하는 tfidf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과일이</th>\n",
       "      <th>길고</th>\n",
       "      <th>노란</th>\n",
       "      <th>먹고</th>\n",
       "      <th>바나나</th>\n",
       "      <th>사과</th>\n",
       "      <th>싶은</th>\n",
       "      <th>저는</th>\n",
       "      <th>좋아요</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   과일이  길고  노란  먹고  바나나  사과  싶은  저는  좋아요\n",
       "0    0   0   0   1    0   1   1   0    0\n",
       "1    0   0   0   1    1   0   1   0    0\n",
       "2    0   1   1   0    2   0   0   0    0\n",
       "3    1   0   0   0    0   0   0   1    1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이제 TF를 구해보겠습니다. DTM을 데이터 프레임에 저장하는 겁니다.\n",
    "\n",
    "result = [] # 빈 객체 만들어 두고.\n",
    "for i in range(N): # 문서 개수만큼 반복합니다. 여기서는 4개.\n",
    "    result.append([]) # 각 문서마다 result 리스트 넣어줍니다.\n",
    "    d = docs[i] # d 는 문서의 숫자쥬?\n",
    "    for j in range(len(vocab)): # 고유 단어의 수만큼 반복합니다.\n",
    "        t = vocab[j] # 특정 단어를 빼냅니다.\n",
    "        result[-1].append(tf(t, d)) # 특정 문서에 t의 카운트를 넣습니다.\n",
    "\n",
    "tf_ = pd.DataFrame(result, columns = vocab)\n",
    "tf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>과일이</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>길고</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>노란</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>먹고</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>바나나</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>사과</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>싶은</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>저는</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>좋아요</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          IDF\n",
       "과일이  0.693147\n",
       "길고   0.693147\n",
       "노란   0.693147\n",
       "먹고   0.287682\n",
       "바나나  0.287682\n",
       "사과   0.693147\n",
       "싶은   0.287682\n",
       "저는   0.693147\n",
       "좋아요  0.693147"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이제 DTM에 대한 IDF 값을 구해봅니다.\n",
    "\n",
    "result = []\n",
    "for j in range(len(vocab)):\n",
    "    t = vocab[j]\n",
    "    result.append(idf(t))\n",
    "    \n",
    "idf_ = pd.DataFrame(result, index = vocab, columns = [\"IDF\"])\n",
    "idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과일이</th>\n",
       "      <th>길고</th>\n",
       "      <th>노란</th>\n",
       "      <th>먹고</th>\n",
       "      <th>바나나</th>\n",
       "      <th>사과</th>\n",
       "      <th>싶은</th>\n",
       "      <th>저는</th>\n",
       "      <th>좋아요</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        과일이        길고        노란        먹고       바나나        사과        싶은  \\\n",
       "0  0.000000  0.000000  0.000000  0.287682  0.000000  0.693147  0.287682   \n",
       "1  0.000000  0.000000  0.000000  0.287682  0.287682  0.000000  0.287682   \n",
       "2  0.000000  0.693147  0.693147  0.000000  0.575364  0.000000  0.000000   \n",
       "3  0.693147  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         저는       좋아요  \n",
       "0  0.000000  0.000000  \n",
       "1  0.000000  0.000000  \n",
       "2  0.000000  0.000000  \n",
       "3  0.693147  0.693147  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이제 TF-IDF 행렬을 출력해봅니다.\n",
    "\n",
    "result = []\n",
    "for i in range(N):\n",
    "    result.append([])\n",
    "    d = docs[i]\n",
    "    for j in range(len(vocab)):\n",
    "        t = vocab[j]\n",
    "        \n",
    "        result[-1].append(tfidf(t,d))\n",
    "        \n",
    "tfidf_ = pd.DataFrame(result, columns = vocab)\n",
    "tfidf_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3. 사이킷런을 이용한 DTM과 TF-IDF 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'you know I want your love',\n",
    "    'I like you',\n",
    "    'what should I do ',    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 1 0 1 1]\n",
      " [0 0 1 0 0 0 0 1 0]\n",
      " [1 0 0 0 1 0 1 0 0]]\n",
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "vector = CountVectorizer()\n",
    "print(vector.fit_transform(corpus).toarray())\n",
    "print(vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 심지어 사이킷런은 TF-IDF를 자동 계산 해주는 TfidVectorizer를 제공합니다.\n",
    "# 다만 기본식에서 IDF의 로그항의 분자에 1을 더해주고, 로그항에 1을 더해주고, TF-IDF에 L2정규화를 줍니다.\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46735098 0.         0.46735098 0.         0.46735098\n",
      "  0.         0.35543247 0.46735098]\n",
      " [0.         0.         0.79596054 0.         0.         0.\n",
      "  0.         0.60534851 0.        ]\n",
      " [0.57735027 0.         0.         0.         0.57735027 0.\n",
      "  0.57735027 0.         0.        ]]\n",
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "tfidfv = TfidfVectorizer().fit(corpus)\n",
    "print(tfidfv.transform(corpus).toarray())\n",
    "print(tfidfv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
