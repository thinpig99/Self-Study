{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05) 정규 표현식(Regular Expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규 표현식 모듈 re의 사용법과 nltk를 통한 정규 표현식 토큰화에 대해 알아보겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05.1. 정규 표현식 문법과 모듈 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규 표현식은 한 번만 읽어보겠습니다.\n",
    "\n",
    "- . 한 개의 임의의 문자\n",
    "- ? 앞에 문자가 존재할 수도, 존재하지 않을 수도\n",
    "- '*' 앞의 문자가 무한개로 존재할 수도, 존재하지 않을 수도\n",
    "- '+' 앞의 문자가 최소 한 개 이상 존재\n",
    "- ^ 뒤의 문자로 문자열이 시작\n",
    "- $ 앞의 문자로 문자열이 끝남\n",
    "- {숫자} 숫자만큼 반복\n",
    "- {숫자1, 숫자2} 숫자1 이상 숫자2 이하만큼 반복.\n",
    "- {숫자,} 숫자 이상만큼 반복\n",
    "- [] 대괄호 안의 문자들 중 한 개의 문자와 매치합니다. [amk] 라고 하면 a, m, k 중 하나라도 존재하면 매치를 의미.\n",
    "- [^문자] 해당 문자를 제외한 문자를 매치\n",
    "- | A|B와 같이 쓰이며 A또는 B의 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문자 규칙입니다.\n",
    "\n",
    "- \\\\ 역 슬래쉬 문자 자체를 의미\n",
    "- \\d 모든 숫자를 의미\n",
    "- \\D 숫자를 제외한 모든 문자\n",
    "- \\s 공백을 의미\n",
    "- \\S 공백을 제외한 문자를 의미\n",
    "- \\w 문자 또는 숫자를 의미\n",
    "- \\W 문자 또는 숫자가 아닌 문자를 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규 표현식 모듈 함수입니다.\n",
    "\n",
    "- re.compile() 컴파일 함수\n",
    "- re.search() 문자열 전체에 대해서 정규표현식과 매치되는지를 검색\n",
    "- re.match() 문자열의 처음이 정규표현식과 매치되는지를 검색\n",
    "- re.split() 정규 표현식을 기준으로 문자열을 분리하여 리스트로 리턴\n",
    "- re.findall() 문자열에서 정규 표현식과 매치되는 모든 경우의 문자열을 찾아서 리스트로 리턴\n",
    "- re.finditer() 문자열에서 정규 표현식과 매치되는 모든 경우의 문자열에 대한 이터레이터 객체를 리턴\n",
    "- re.sub() 문자열에서 정규 표현식과 일치하는 부분에 대해서 다른 문자열로 대체."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05.2. 정규 표현식 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05.2.1. .기호"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". 한 개의 임의의 문자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(\"a.c\")\n",
    "r.search(\"kkk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='abc'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='akc'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"akc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". 을 문자로 인식하기에 어떤 문자가 들어와도 매치를 시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05.2.2. ?기호"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "? 앞에 문자가 존재할 수도, 존재하지 않을 수도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(\"ab?c\") # b는 존재할 수도, 존재하지 않을 수도.\n",
    "r.search(\"abbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='abc'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 2), match='ac'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"ac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b가 없는 것으로 판단하여 ac를 매치하는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05.2.3. *기호"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'*' 앞의 문자가 무한개로 존재할 수도, 존재하지 않을 수도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(\"ab*c\")\n",
    "r.search(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 2), match='ac'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"ac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='abc'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 6), match='abbbbc'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abbbbc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b는 존재하지 않을 수도 무한개로 존재할 수도 있으니 위와 같이 매치시킵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05.2.4. +기호"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'+' 앞의 문자가 최소 한 개 이상 존재, '*'와 비슷하지만 최소 1개 있어야 한다는 조건이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(\"ab+c\")\n",
    "r.search(\"ac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='abc'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 7), match='abbbbbc'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abbbbbc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ac 는 매치하지 않고, abc 부터 매치하는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05.2.5. ^기호"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ 뒤의 문자로 문자열이 시작, 시작되는 글자를 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(\"^a\")\n",
    "r.search(\"bbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='a'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"ab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05.2.6. $ 기호"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ 앞의 문자로 문자열이 끝남, ^와 반대라고 보면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(\"a$\")\n",
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(2, 3), match='a'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"cba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05.2.7. {숫자} 기호"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{숫자} 숫자만큼 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(\"ab{2}c\")\n",
    "r.search(\"ac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='abbc'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.search(\"abbbbbc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오직 숫자만큼만 반복되어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05.2.8. {숫자1, 숫자2} 기호"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{숫자1, 숫자2} 숫자1 이상 숫자2 이하만큼 반복."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(\"ab{2,8}c\")\n",
    "r.search(\"ac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='abbc'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 9), match='abbbbbbbc'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abbbbbbbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.search(\"abbbbbbbbbbc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05.2.9. {숫자,}기호"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{숫자,} 숫자 이상만큼 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(\"a{2,}bc\")\n",
    "r.search(\"bc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.search(\"aa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='aabc'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"aabc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 11), match='aaaaaaaaabc'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"aaaaaaaaabc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뒤에 bc가 있으면서 a가 2회 이상 반복되어야 한다. {0,}은 '*'와 동일하며 {1,}은 '+'와 동일하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05.2.10. []기호"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[] 대괄호 안의 문자들 중 한 개의 문자와 매치합니다. [amk] 라고 하면 a, m, k 중 하나라도 존재하면 매치를 의미.\n",
    "\n",
    "\n",
    "[a-zA-Z] 는 알파벳 전부를 의미, [0-9]는 숫자 전부를 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(\"[abc]\") # [abc]는 [a-c]와 같다.\n",
    "r.search(\"zzz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='a'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='a'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"aaaaaaa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='b'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"baac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.search(\"dddddd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "알파벳 소문자에 대해서만 범위 지정해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(\"[a-z]\")\n",
    "r.search(\"AAA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='a'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"aBC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.search(\"111\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05.2.11. [^문자] 기호"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[^문자] 해당 문자를 제외한 문자를 매치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(\"[^abc]\")\n",
    "r.search(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.search(\"ab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.search(\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='d'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='1'>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05.2.12. | 기호"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| A|B와 같이 쓰이며 A또는 B의 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='a'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = re.compile(\"a|b\")\n",
    "r.search(\"ab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='a'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='b'>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.search(\"c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05.3. 정규 표현식 모듈 함수 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 re.compile(), re.search()을 알아보았습니다. 다른 것도 알아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05.3.1. re.match()와 re.search()의 차이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "search()가 정규 표현식 전체에 대해서 문자열이 매치하는지를 본다면,\n",
    "\n",
    "match()는 문자열의 첫 부분부터 정규 표현식과 매치하는지를 확인합니다.\n",
    "\n",
    "즉, 중간에 패턴이 있더라도 match는 찾지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(\"ab.\") #.은 임의의 문자로 인식."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(3, 6), match='abc'>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"kkkabc\") # 서치는 abc가 뒤에 있어도 매치로 인식."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.match(\"kkkabc\") # 매치는 abc가 뒤에 있으니 매치 하지 않음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='abc'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.match(\"abckkk\") # 앞에 abc로 시작하니 매치하는 것으로 인식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05.3.2. re.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "re.split()은 입력된 정규 표현식을 기준으로 문자열들을 분리하여 리스트로 리턴한다.\n",
    "\n",
    "토큰화에 유용하게 쓰인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"사과 딸기 수박 메론 바나나 파인애플\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['사과', '딸기', '수박', '메론', '바나나', '파인애플']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(\" \", corpus) # 공백으로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['사과', '딸기', '수박', '메론', '바나나']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = \"\"\"사과\n",
    "딸기\n",
    "수박\n",
    "메론\n",
    "바나나\"\"\"\n",
    "re.split(\"\\n\",corpus) # 줄바꿈으로 리턴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['사과', '딸기', '수박', '메론', '바나나']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus=\"사과+딸기+수박+메론+바나나\"\n",
    "re.split(\"\\+\",corpus) #더하기로 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05.3.3. re.findall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "findall()은 정규표현식과 매치되는 모든 문자열들을 리스트로 리턴.\n",
    "\n",
    "단, 매치되는 문자열이 없다면 빈 리스트."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['010', '1234', '1234', '30']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = \"\"\"이름 : 김철수\n",
    "전화번호 : 010 - 1234 - 1234\n",
    "나이 : 30\n",
    "성별 : 남\"\"\"\n",
    "re.findall(\"\\d+\", corpus) #\\d 는 숫자를 의미. +는 앞의 문자가 최소 1개 이상 존재, 즉 숫자가 1개라도 있으면 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"\\d+\", \"문자열입니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05.3.4. re.sub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sub() 함수는 정규 표현식 패턴과 일치하는 문자열을 찾아 다른 문자열로 대체한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Regular expression   A regular expression  regex or regexp     sometimes called a rational expression        is  in theoretical computer science and formal language theory  a sequence of characters that define a search pattern '"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus=\"\"\"Regular expression : A regular expression,\n",
    "regex or regexp[1] (sometimes called a rational expression)[2][3] is,\n",
    "in theoretical computer science and formal language theory,\n",
    "a sequence of characters that define a search pattern.\"\"\"\n",
    "\n",
    "re.sub('[^a-zA-Z]',' ',corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "알파벳이 아닌 문자를 공백으로 처리 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05.6. 정규 표현식을 이용한 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK에서는 정규 표현식을 사용해서 단어 토큰화를 수행하는 RegexpTokenizer를 지원합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(\"[\\w]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Don', 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'Mr', 'Jone', 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\w 는 문자또는 숫자. +는 1개 이상. 즉 특수문자를 제외한 모든 숫자와 문자를 반환합니다. 그래서 Don, t 로 분리되었죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=RegexpTokenizer(\"[\\s]+\", gaps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name,', 'Mr.', \"Jone's\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\s 공백을 기준으로 토큰화 했습니다. Don't로 분리 되었습니다. gaps=True는 토큰화 한다는 뜻입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=RegexpTokenizer(\"[\\s]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gaps=True 조건을 넣지 않으니 조건으로만 반환하죠?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06) 정수 인코딩(Integer Encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컴퓨터는 텍스트보다는 숫자를 더 잘 처리하기 때문에 텍스트를 숫자로 바꾸는 여러 기법들이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06.1. 정수 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어에 정수를 부여하는 방법 중 하나로 단어를 빈도수 순으로 정렬한 단어 집합을 만들고, 빈도수가 높은 순서대로 차례로 낮은 숫자부터 정수를 부여하는 방법이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 06.1.1. dictionary 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"A barber is a person. a barber is good person. a barber is huge person.\n",
    "he Knew A Secret! The Secret He Kept is huge secret. Huge secret.\n",
    "His barber kept his word. a barber kept his word. His barber kept his secret.\n",
    "But keeping and keeping such a huge secret to himself was driving the barber crazy.\n",
    "the barber went up a huge mountain.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A barber is a person.', 'a barber is good person.', 'a barber is huge person.', 'he Knew A Secret!', 'The Secret He Kept is huge secret.', 'Huge secret.', 'His barber kept his word.', 'a barber kept his word.', 'His barber kept his secret.', 'But keeping and keeping such a huge secret to himself was driving the barber crazy.', 'the barber went up a huge mountain.']\n"
     ]
    }
   ],
   "source": [
    "# 문장 토큰화\n",
    "corpus = sent_tokenize(corpus)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장 단위로 토큰화 된 것을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
     ]
    }
   ],
   "source": [
    "# 정제와 단어 토큰화\n",
    "vocab = {} # 딕셔러리\n",
    "sentences = []\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for i in corpus:\n",
    "    sentence = word_tokenize(i) # 단어 토큰화\n",
    "    result = []\n",
    "    \n",
    "    for word in sentence:\n",
    "        word = word.lower() # 모든 단어 소문자화하여 단어의 개수를 줄입니다.\n",
    "        if word not in stop_words: # 불용어 제거\n",
    "            if len(word) > 2: # 단어 길이에 따른 제거\n",
    "                result.append(word) # 조건을 마치면 result에 어펜드.\n",
    "                if word not in vocab: # 딕셔너리에 없으면.\n",
    "                    vocab[word] = 0 # 딕셔너리에 할당합니다.\n",
    "                vocab[word] +=1 # 그리고 한개를 더한다.\n",
    "    sentences.append(result)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 8, 'person': 3, 'good': 1, 'huge': 5, 'knew': 1, 'secret': 6, 'kept': 4, 'word': 2, 'keeping': 2, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1}\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(vocab['barber'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 빈도수가 높은 순서대로 정렬해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sorted = sorted(vocab.items(), key = lambda x:x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2), ('good', 1), ('knew', 1), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(vocab_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 높은 빈도수를 가진 단어일수록 낮은 정수 인덱스를 부여합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7}\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {}\n",
    "i = 0\n",
    "for (word, frequency) in vocab_sorted:\n",
    "    if frequency > 1: # 빈도수가 적은 단어는 제외\n",
    "        i=i+1\n",
    "        word_to_index[word] = i\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다면 빈도수가 가장 높은 상위 5개만 사용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 5\n",
    "\n",
    "# 인덱스가 5 초과인 단어 제거\n",
    "words_frequency = [w for w,c in word_to_index.items() if c >= vocab_size +1]\n",
    "\n",
    "for w in words_frequency:\n",
    "    del word_to_index[w] # 해당 단어에 대한 인덱스 정보 삭제\n",
    "\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 word_to_index를 사용하여 단어 토큰화가 된 상태로 저장된 sentences에 있는 각 단어를 정수로 바꾸는 작업을 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어 sentences에서 첫번째 문장은 ['barber', 'person']이었는데, 이 문장에 대해서는 [1, 5]로 인코딩합니다. 그런데 두번째 문장인 ['barber', 'good', 'person']에는 더 이상 word_to_index에는 존재하지 않는 단어인 'good'이라는 단어가 있습니다.\n",
    "\n",
    "이처럼 단어 집합에 존재하지 않는 단어들을 Out-Of-Vocabulary(단어 집합에 없는 단어)의 약자로 'OOV'라고 합니다. word_to_index에 'OOV'란 단어를 새롭게 추가하고, 단어 집합에 없는 단어들은 'OOV'의 인덱스로 인코딩하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index['OOV'] = len(word_to_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5], [1, 6, 5], [1, 3, 5], [6, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [6, 6, 3, 2, 6, 1, 6], [1, 6, 3, 6]]\n"
     ]
    }
   ],
   "source": [
    "encoded = []\n",
    "for s in sentences:\n",
    "    temp = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            temp.append(word_to_index[w])\n",
    "        except KeyError:\n",
    "            temp.append(word_to_index['OOV'])\n",
    "    encoded.append(temp)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "너무 고생하셨습니다. 하지만 이거 잘 안 씁니다. 핳하핳하"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 06.1.2. Counter 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어들을 하나의 리스트로 만들겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['barber' 'person' 'barber' 'good' 'person' 'barber' 'huge' 'person'\n",
      " 'knew' 'secret' 'secret' 'kept' 'huge' 'secret' 'huge' 'secret' 'barber'\n",
      " 'kept' 'word' 'barber' 'kept' 'word' 'barber' 'kept' 'secret' 'keeping'\n",
      " 'keeping' 'huge' 'secret' 'driving' 'barber' 'crazy' 'barber' 'went'\n",
      " 'huge' 'mountain']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "words = np.hstack(sentences)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 Counter() 를 쓰면 중복을 제거하고 빈도수를 기록합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1})\n"
     ]
    }
   ],
   "source": [
    "vocab = Counter(words)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most_common()은 상위 빈도수를 가진 주어진 수의 단어만을 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 5\n",
    "vocab = vocab.most_common(vocab_size)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {}\n",
    "i = 0\n",
    "for (word, frequency) in vocab :\n",
    "    i = i+1\n",
    "    word_to_index[word] = i\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 06.1.3. NLTK의 FreqDist 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK에서는 빈도수 계산 도구인 FreqDist()를 지원합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = FreqDist(sum(sentences, [])) #np.hstack과 똑같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(vocab[\"barber\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 5\n",
    "vocab = vocab.most_common(vocab_size) # 등장 빈도수가 높은 상위 5개의 단어만 저장\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
     ]
    }
   ],
   "source": [
    "# enumerate()를 사용하겠습니다.\n",
    "\n",
    "word_to_index = {word[0] : index + 1 for index, word in enumerate(vocab)}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 06.1.4. enumerate 이해하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이뉴머레이트는 자료형(리스트, 셋, 튜플, 딕셔너리, 스트링)을 입력받아 인덱스를 순차적으로 함께 리턴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value : a, index: 0\n",
      "value : b, index: 1\n",
      "value : c, index: 2\n",
      "value : d, index: 3\n",
      "value : e, index: 4\n"
     ]
    }
   ],
   "source": [
    "test=['a', 'b', 'c', 'd', 'e']\n",
    "for index, value in enumerate(test): # 입력의 순서대로 0부터 인덱스를 부여함.\n",
    "    print(\"value : {}, index: {}\".format(value, index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06.2. 케라스의 텍스트 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스도 전처리 도구를 제공합니다!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[['barber', 'person'], ['barber', 'good', 'person'],\n",
    "           ['barber', 'huge', 'person'], ['knew', 'secret'],\n",
    "           ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'],\n",
    "           ['barber', 'kept', 'word'], ['barber', 'kept', 'word'],\n",
    "           ['barber', 'kept', 'secret'],\n",
    "           ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'],\n",
    "           ['barber', 'went', 'huge', 'mountain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences) # 빈도수를 기준으로 단어 집합을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain': 13}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index) # 인덱스 부여 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('barber', 8), ('person', 3), ('good', 1), ('huge', 5), ('knew', 1), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)])\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_counts) # 카운트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.texts_to_sequences(sentences)) # 이건 코퍼스를 인덱스로 변환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스도 most_common()처럼 n개의 단어만 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 5\n",
    "tokenizer = Tokenizer(num_words = size +1) # 컴퓨터는 0부터 세는데, 인덱스는 0이 없다. 그래서 1을 더해줘야 5.\n",
    "tokenizer.fit_on_texts(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain': 13}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index) # 근데 인덱스 다 나오는데?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('barber', 8), ('person', 3), ('good', 1), ('huge', 5), ('knew', 1), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)])\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_counts) # 에잉?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5], [1, 5], [1, 3, 5], [2], [2, 4, 3, 2], [3, 2], [1, 4], [1, 4], [1, 4, 2], [3, 2, 1], [1, 3]]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.texts_to_sequences(sentences)) # 하짐만 5까지만 보여주지롱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스 토크나이저는 단어 집합에 없는 단어들을 OOV로 간주하여 보존하고 싶다면 oov_token 인자를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5\n",
    "tokenizer = Tokenizer(num_words = vocab_size + 2, oov_token = 'OOV')\n",
    "# 빈도수 상위 5개 단어만 사용. 숫자 0과 OOV를 고려해서 단어 집합의 크기는 +2\n",
    "tokenizer.fit_on_texts(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index['OOV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 6], [2, 1, 6], [2, 4, 6], [1, 3], [3, 5, 4, 3], [4, 3], [2, 5, 1], [2, 5, 1], [2, 5, 3], [1, 1, 4, 3, 1, 2, 1], [2, 1, 4, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.texts_to_sequences(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
