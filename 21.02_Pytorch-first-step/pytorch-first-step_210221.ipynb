{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "continuous-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "alike-filename",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-contents",
   "metadata": {},
   "source": [
    "## 3. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "shared-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 1000\n",
    "num_epoch = 500\n",
    "\n",
    "x = init.uniform_(torch.Tensor(num_data, 1), -10, 10)\n",
    "noise = init.normal_(torch.FloatTensor(num_data, 1), std=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "neutral-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 2*x + 3\n",
    "y_noise = y + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rural-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1, 1)\n",
    "loss_func = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "limiting-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "prompt-limit",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.8946)\n",
      "-0.46504348516464233 0.48894214630126953\n",
      "-0.41519105434417725 0.4902021586894989\n",
      "-0.36533862352371216 0.49146217107772827\n",
      "-0.31548619270324707 0.49272218346595764\n",
      "-0.265633761882782 0.493982195854187\n",
      "-0.2157813459634781 0.4952422082424164\n",
      "-0.1659504771232605 0.4965222179889679\n",
      "-0.1161196157336235 0.4978022277355194\n",
      "-0.06630033254623413 0.49910223484039307\n",
      "-0.016551831737160683 0.5004622340202332\n",
      "tensor(10.4096)\n",
      "0.03314098343253136 0.5018622279167175\n",
      "0.08280825614929199 0.5032822489738464\n",
      "0.13247552514076233 0.5047022700309753\n",
      "0.18214279413223267 0.5061222910881042\n",
      "0.23173415660858154 0.5075823068618774\n",
      "0.2812044024467468 0.5091223120689392\n",
      "0.33057478070259094 0.5107223391532898\n",
      "0.37981656193733215 0.5123823285102844\n",
      "0.42897412180900574 0.5140823125839233\n",
      "0.47798484563827515 0.5158423185348511\n",
      "tensor(7.9631)\n",
      "0.5269955992698669 0.5176023244857788\n",
      "0.5760063529014587 0.5193623304367065\n",
      "0.6250171065330505 0.5211223363876343\n",
      "0.6739062666893005 0.5229423642158508\n",
      "0.7227456569671631 0.5247823596000671\n",
      "0.7715850472450256 0.5266223549842834\n",
      "0.8202865123748779 0.5285423398017883\n",
      "0.8686911463737488 0.5305623412132263\n",
      "0.9167706370353699 0.5327223539352417\n",
      "0.9644860029220581 0.5350023508071899\n",
      "tensor(5.5959)\n",
      "1.0118963718414307 0.537402331829071\n",
      "1.0590349435806274 0.5398823022842407\n",
      "1.1059807538986206 0.5424222946166992\n",
      "1.1522499322891235 0.5451623201370239\n",
      "1.1978977918624878 0.5481023192405701\n",
      "1.2429542541503906 0.5512022972106934\n",
      "1.2875831127166748 0.55438232421875\n",
      "1.331660509109497 0.5577023029327393\n",
      "1.374967336654663 0.5612223148345947\n",
      "1.4175251722335815 0.5649223327636719\n",
      "tensor(3.5450)\n",
      "1.459058403968811 0.5688623189926147\n",
      "1.4982749223709106 0.5732623338699341\n",
      "1.5359346866607666 0.5779223442077637\n",
      "1.5712558031082153 0.5830023288726807\n",
      "1.6041220426559448 0.5884623527526855\n",
      "1.634284496307373 0.5944223403930664\n",
      "1.6606230735778809 0.6009223461151123\n",
      "1.6838892698287964 0.6078623533248901\n",
      "1.7052768468856812 0.6150823831558228\n",
      "1.7246845960617065 0.6226024031639099\n",
      "tensor(2.5469)\n",
      "1.741684913635254 0.6304423809051514\n",
      "1.7568511962890625 0.6385423541069031\n",
      "1.7700632810592651 0.6468623280525208\n",
      "1.7815039157867432 0.6554023027420044\n",
      "1.7925399541854858 0.6640022993087769\n",
      "1.8022582530975342 0.672782301902771\n",
      "1.8114625215530396 0.681622326374054\n",
      "1.820086121559143 0.6905423402786255\n",
      "1.827663540840149 0.6995823383331299\n",
      "1.8346284627914429 0.7087023258209229\n",
      "tensor(2.3479)\n",
      "1.841249704360962 0.7178623080253601\n",
      "1.8470875024795532 0.7271223068237305\n",
      "1.8527339696884155 0.7364023327827454\n",
      "1.858218789100647 0.7456823587417603\n",
      "1.8633685111999512 0.7549623847007751\n",
      "1.8683346509933472 0.7642623782157898\n",
      "1.873119831085205 0.773582398891449\n",
      "1.8775203227996826 0.7829623818397522\n",
      "1.8816583156585693 0.7923823595046997\n",
      "1.8856680393218994 0.8018223643302917\n",
      "tensor(2.2353)\n",
      "1.8895485401153564 0.8112423419952393\n",
      "1.8932592868804932 0.8206223249435425\n",
      "1.8969700336456299 0.8300023078918457\n",
      "1.9005111455917358 0.8394023180007935\n",
      "1.9040522575378418 0.8488023281097412\n",
      "1.9074536561965942 0.8582223057746887\n",
      "1.9107348918914795 0.8676623106002808\n",
      "1.9140218496322632 0.8770822882652283\n",
      "1.9169976711273193 0.8865422606468201\n",
      "1.9195702075958252 0.8960222601890564\n",
      "tensor(2.1351)\n",
      "1.9220043420791626 0.9054822325706482\n",
      "1.9242596626281738 0.9149622321128845\n",
      "1.926514983177185 0.9244422316551208\n",
      "1.9287703037261963 0.9339222311973572\n",
      "1.9310256242752075 0.9434022307395935\n",
      "1.9330925941467285 0.9529022574424744\n",
      "1.9351595640182495 0.9624022841453552\n",
      "1.9372265338897705 0.9719023108482361\n",
      "1.9391930103302002 0.9813823103904724\n",
      "1.9411594867706299 0.9908623099327087\n",
      "tensor(2.0406)\n",
      "1.9429621696472168 1.0003223419189453\n",
      "1.9445892572402954 1.0098023414611816\n",
      "1.946216344833374 1.019282341003418\n",
      "1.9478434324264526 1.0287623405456543\n",
      "1.9494705200195312 1.0382423400878906\n",
      "1.951070785522461 1.0477023124694824\n",
      "1.9526710510253906 1.0571622848510742\n",
      "1.9542713165283203 1.066622257232666\n",
      "1.95587158203125 1.0760822296142578\n",
      "1.957453966140747 1.085522174835205\n",
      "tensor(1.9484)\n",
      "1.9589813947677612 1.0949422121047974\n",
      "1.9602724313735962 1.1043221950531006\n",
      "1.9615634679794312 1.1137021780014038\n",
      "1.9628545045852661 1.123082160949707\n",
      "1.9640202522277832 1.1324421167373657\n",
      "1.9651859998703003 1.1418020725250244\n",
      "1.966387152671814 1.1511421203613281\n",
      "1.9675883054733276 1.1604821681976318\n",
      "1.9687894582748413 1.1698222160339355\n",
      "1.9700638055801392 1.1791422367095947\n",
      "tensor(1.8592)\n",
      "1.971338152885437 1.188462257385254\n",
      "1.9726125001907349 1.197782278060913\n",
      "1.9738868474960327 1.2071022987365723\n",
      "1.9751644134521484 1.216402292251587\n",
      "1.9764419794082642 1.2257022857666016\n",
      "1.977460503578186 1.2349623441696167\n",
      "1.978479027748108 1.2442224025726318\n",
      "1.9794975519180298 1.253482460975647\n",
      "1.9806323051452637 1.2627224922180176\n",
      "1.9817670583724976 1.2719625234603882\n",
      "tensor(1.7716)\n",
      "1.9829018115997314 1.2812025547027588\n",
      "1.983859896659851 1.2904225587844849\n",
      "1.9849330186843872 1.2996025085449219\n",
      "1.9858189821243286 1.308762550354004\n",
      "1.98670494556427 1.317922592163086\n",
      "1.9876272678375244 1.3270626068115234\n",
      "1.9885495901107788 1.336202621459961\n",
      "1.9894719123840332 1.3453426361083984\n",
      "1.9903942346572876 1.354482650756836\n",
      "1.991316556930542 1.3636226654052734\n",
      "tensor(1.6868)\n",
      "1.9922995567321777 1.3727226257324219\n",
      "1.9932825565338135 1.3818225860595703\n",
      "1.9942597150802612 1.3908625841140747\n",
      "1.995059609413147 1.3998825550079346\n",
      "1.995789885520935 1.40888249874115\n",
      "1.9965201616287231 1.4178824424743652\n",
      "1.9972504377365112 1.4268624782562256\n",
      "1.9979649782180786 1.4358224868774414\n",
      "1.9987212419509888 1.4447624683380127\n",
      "1.999477505683899 1.453702449798584\n",
      "tensor(1.6051)\n",
      "1.9999710321426392 1.4626024961471558\n",
      "2.00046443939209 1.4715025424957275\n",
      "2.001002311706543 1.4803825616836548\n",
      "2.001540184020996 1.489262580871582\n",
      "2.002117156982422 1.4981225728988647\n",
      "2.0026941299438477 1.5069825649261475\n",
      "2.0029447078704834 1.5157825946807861\n",
      "2.00319766998291 1.5245625972747803\n",
      "2.0031096935272217 1.5333025455474854\n",
      "2.0033607482910156 1.5419825315475464\n",
      "tensor(1.5270)\n",
      "2.003655433654785 1.550622582435608\n",
      "2.003924608230591 1.5592225790023804\n",
      "2.004244804382324 1.5677825212478638\n",
      "2.004685640335083 1.5763225555419922\n",
      "2.0051119327545166 1.584842562675476\n",
      "2.0054385662078857 1.5933425426483154\n",
      "2.0058934688568115 1.6018224954605103\n",
      "2.0059943199157715 1.610242486000061\n",
      "2.0060951709747314 1.6186624765396118\n",
      "2.0060834884643555 1.627062439918518\n",
      "tensor(1.4547)\n",
      "2.006105661392212 1.6354424953460693\n",
      "2.00607967376709 1.643802523612976\n",
      "2.0060536861419678 1.6521625518798828\n",
      "2.0057477951049805 1.6604825258255005\n",
      "2.0058090686798096 1.6687625646591187\n",
      "2.0058703422546387 1.6770426034927368\n",
      "2.0059316158294678 1.685322642326355\n",
      "2.0059561729431152 1.6935826539993286\n",
      "2.0059800148010254 1.7018226385116577\n",
      "2.0060038566589355 1.7100626230239868\n",
      "tensor(1.3858)\n",
      "2.006169557571411 1.7182825803756714\n",
      "2.0063352584838867 1.726502537727356\n",
      "2.0065038204193115 1.7347025871276855\n",
      "2.006824493408203 1.742862582206726\n",
      "2.0070853233337402 1.751002550125122\n",
      "2.007246494293213 1.7591224908828735\n",
      "2.0072028636932373 1.7672024965286255\n",
      "2.0071592330932617 1.7752825021743774\n",
      "2.006938934326172 1.7833224534988403\n",
      "2.006945848464966 1.7913024425506592\n",
      "tensor(1.3199)\n",
      "2.0069527626037598 1.799282431602478\n",
      "2.0066628456115723 1.8072224855422974\n",
      "2.006446599960327 1.8151224851608276\n",
      "2.005957841873169 1.8229424953460693\n",
      "2.005394697189331 1.830722451210022\n",
      "2.005031108856201 1.838462471961975\n",
      "2.004800796508789 1.8461824655532837\n",
      "2.004650592803955 1.8538824319839478\n",
      "2.00434947013855 1.8615624904632568\n",
      "2.0040109157562256 1.8691824674606323\n",
      "tensor(1.2593)\n",
      "2.003866672515869 1.8767224550247192\n",
      "2.0037224292755127 1.8842624425888062\n",
      "2.003711462020874 1.8917824029922485\n",
      "2.003613233566284 1.8992424011230469\n",
      "2.0033206939697266 1.9066823720932007\n",
      "2.003028154373169 1.9141223430633545\n",
      "2.0027356147766113 1.9215623140335083\n",
      "2.0023844242095947 1.928942322731018\n",
      "2.0018084049224854 1.9362623691558838\n",
      "2.0012528896331787 1.943502426147461\n",
      "tensor(1.2041)\n",
      "2.000697374343872 1.950742483139038\n",
      "1.9999479055404663 1.9579625129699707\n",
      "1.9993788003921509 1.9651224613189697\n",
      "1.998741626739502 1.9722625017166138\n",
      "1.998483419418335 1.9793025255203247\n",
      "1.9984160661697388 1.9863024950027466\n",
      "1.9984822273254395 1.9932425022125244\n",
      "1.998429536819458 2.000122547149658\n",
      "1.9983022212982178 2.0069825649261475\n",
      "1.9981749057769775 2.0138425827026367\n",
      "tensor(1.1546)\n",
      "1.9979430437088013 2.0206425189971924\n",
      "1.9979078769683838 2.0273826122283936\n",
      "1.997833490371704 2.034062623977661\n",
      "1.9977591037750244 2.0407426357269287\n",
      "1.9976024627685547 2.0473825931549072\n",
      "1.997445821762085 2.0540225505828857\n",
      "1.9972989559173584 2.060622453689575\n",
      "1.9970589876174927 2.067202568054199\n",
      "1.996673583984375 2.073742628097534\n",
      "1.9964573383331299 2.0802626609802246\n",
      "tensor(1.1105)\n",
      "1.9962410926818848 2.086782693862915\n",
      "1.9960283041000366 2.0932626724243164\n",
      "1.9960849285125732 2.0997025966644287\n",
      "1.996239423751831 2.1061224937438965\n",
      "1.9963939189910889 2.1125423908233643\n",
      "1.9965589046478271 2.1189424991607666\n",
      "1.9968113899230957 2.1253225803375244\n",
      "1.9969782829284668 2.131662607192993\n",
      "1.9965298175811768 2.137882709503174\n",
      "1.9960196018218994 2.1440227031707764\n",
      "tensor(1.0699)\n",
      "1.9956597089767456 2.1501426696777344\n",
      "1.9954382181167603 2.1561827659606934\n",
      "1.9954537153244019 2.1621828079223633\n",
      "1.9953027963638306 2.1681227684020996\n",
      "1.9952384233474731 2.1740427017211914\n",
      "1.9953159093856812 2.1799426078796387\n",
      "1.995499849319458 2.1858227252960205\n",
      "1.9958280324935913 2.191682815551758\n",
      "1.9961615800857544 2.1975228786468506\n",
      "1.9960945844650269 2.2032628059387207\n",
      "tensor(1.0349)\n",
      "1.9960275888442993 2.209002733230591\n",
      "1.9957877397537231 2.2147226333618164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.995547890663147 2.220442533493042\n",
      "1.9952908754348755 2.2261226177215576\n",
      "1.9952963590621948 2.2317426204681396\n",
      "1.9953757524490356 2.237342596054077\n",
      "1.9954150915145874 2.242882490158081\n",
      "1.9952951669692993 2.2484025955200195\n",
      "1.9952685832977295 2.2539026737213135\n",
      "1.9952304363250732 2.259382724761963\n",
      "tensor(1.0034)\n",
      "1.9950658082962036 2.2648427486419678\n",
      "1.9948376417160034 2.2702627182006836\n",
      "1.9946962594985962 2.2756426334381104\n",
      "1.994554877281189 2.281022548675537\n",
      "1.9944134950637817 2.286402463912964\n",
      "1.9942721128463745 2.2917823791503906\n",
      "1.9939152002334595 2.2970824241638184\n",
      "1.9935582876205444 2.302382469177246\n",
      "1.9933762550354004 2.3076624870300293\n",
      "1.9929752349853516 2.3129024505615234\n",
      "tensor(0.9748)\n",
      "1.9925682544708252 2.318082332611084\n",
      "1.9921612739562988 2.3232622146606445\n",
      "1.991828203201294 2.328402280807495\n",
      "1.9924460649490356 2.3334221839904785\n",
      "1.9928654432296753 2.3384621143341064\n",
      "1.9930094480514526 2.3434622287750244\n",
      "1.9934672117233276 2.3484222888946533\n",
      "1.993524432182312 2.3533222675323486\n",
      "1.993514895439148 2.3582022190093994\n",
      "1.993312120437622 2.3630621433258057\n",
      "tensor(0.9496)\n",
      "1.9930741786956787 2.3679020404815674\n",
      "1.9928362369537354 2.372741937637329\n",
      "1.9927507638931274 2.3774819374084473\n",
      "1.9926652908325195 2.3822219371795654\n",
      "1.9926632642745972 2.3869218826293945\n",
      "1.9928454160690308 2.391601800918579\n",
      "1.9930275678634644 2.3962817192077637\n",
      "1.9930329322814941 2.4009416103363037\n",
      "1.9929677248001099 2.4055817127227783\n",
      "1.9928267002105713 2.4102017879486084\n",
      "tensor(0.9274)\n",
      "1.9930028915405273 2.4147818088531494\n",
      "1.9932150840759277 2.419301748275757\n",
      "1.9935153722763062 2.4238016605377197\n",
      "1.9936710596084595 2.4281816482543945\n",
      "1.993631362915039 2.4325215816497803\n",
      "1.9935916662216187 2.436861515045166\n",
      "1.9937855005264282 2.4411416053771973\n",
      "1.9938443899154663 2.445401668548584\n",
      "1.9942413568496704 2.4496216773986816\n",
      "1.9946858882904053 2.453761577606201\n",
      "tensor(0.9085)\n",
      "1.9949233531951904 2.457841634750366\n",
      "1.9953452348709106 2.4619016647338867\n",
      "1.9957671165466309 2.4659616947174072\n",
      "1.996188998222351 2.4700217247009277\n",
      "1.9964485168457031 2.4740617275238037\n",
      "1.9967728853225708 2.478081703186035\n",
      "1.9969432353973389 2.482081651687622\n",
      "1.997113585472107 2.486081600189209\n",
      "1.9973623752593994 2.4900615215301514\n",
      "1.99741530418396 2.494021415710449\n",
      "tensor(0.8922)\n",
      "1.9974513053894043 2.4979615211486816\n",
      "1.997625708580017 2.5018815994262695\n",
      "1.9977712631225586 2.5057616233825684\n",
      "1.9982258081436157 2.5095815658569336\n",
      "1.9987274408340454 2.5133614540100098\n",
      "1.999229073524475 2.517141342163086\n",
      "1.9996874332427979 2.5209014415740967\n",
      "2.000225067138672 2.524601459503174\n",
      "2.000601053237915 2.5282814502716064\n",
      "2.0007576942443848 2.531881332397461\n",
      "tensor(0.8778)\n",
      "2.0010294914245605 2.53546142578125\n",
      "2.001213788986206 2.5390214920043945\n",
      "2.0013980865478516 2.542581558227539\n",
      "2.001488447189331 2.5461015701293945\n",
      "2.0015788078308105 2.54962158203125\n",
      "2.001476526260376 2.553081512451172\n",
      "2.0013742446899414 2.5565414428710938\n",
      "2.001271963119507 2.5600013732910156\n",
      "2.001373767852783 2.5634214878082275\n",
      "2.001333236694336 2.566821575164795\n",
      "tensor(0.8656)\n",
      "2.0014309883117676 2.5702016353607178\n",
      "2.001539945602417 2.573561668395996\n",
      "2.0013861656188965 2.576861619949341\n",
      "2.0011661052703857 2.580141544342041\n",
      "2.0010807514190674 2.5834014415740967\n",
      "2.000908374786377 2.5866215229034424\n",
      "2.0007622241973877 2.5898215770721436\n",
      "2.000753164291382 2.5930016040802\n",
      "2.000908374786377 2.5961616039276123\n",
      "2.0008864402770996 2.59930157661438\n",
      "tensor(0.8551)\n",
      "2.0008645057678223 2.6024415493011475\n",
      "2.0008761882781982 2.6055614948272705\n",
      "2.001077890396118 2.6086413860321045\n",
      "2.001270055770874 2.611701488494873\n",
      "2.00146222114563 2.6147615909576416\n",
      "2.001790761947632 2.6178016662597656\n",
      "2.001926898956299 2.6208016872406006\n",
      "2.002063035964966 2.6238017082214355\n",
      "2.0020360946655273 2.626781702041626\n",
      "2.0019428730010986 2.629741668701172\n",
      "tensor(0.8458)\n",
      "2.0018563270568848 2.632641553878784\n",
      "2.001769781112671 2.6355414390563965\n",
      "2.0017924308776855 2.6384215354919434\n",
      "2.0018150806427 2.6413016319274902\n",
      "2.001985788345337 2.644141674041748\n",
      "2.0019383430480957 2.646941661834717\n",
      "2.0018908977508545 2.6497416496276855\n",
      "2.0016887187957764 2.6525216102600098\n",
      "2.001640558242798 2.6552815437316895\n",
      "2.0015923976898193 2.658041477203369\n",
      "tensor(0.8378)\n",
      "2.00136137008667 2.6607813835144043\n",
      "2.0012335777282715 2.663501501083374\n",
      "2.00112247467041 2.6661815643310547\n",
      "2.001011371612549 2.6688616275787354\n",
      "2.001063823699951 2.6715216636657715\n",
      "2.0007505416870117 2.6741416454315186\n",
      "2.0004372596740723 2.6767616271972656\n",
      "2.000206232070923 2.679361581802368\n",
      "2.0000486373901367 2.6819214820861816\n",
      "1.9999916553497314 2.6844615936279297\n",
      "tensor(0.8308)\n",
      "1.9999346733093262 2.6870017051696777\n",
      "1.999983310699463 2.6895217895507812\n",
      "1.9999758005142212 2.6920018196105957\n",
      "1.9999682903289795 2.69448184967041\n",
      "2.0000014305114746 2.69694185256958\n",
      "2.0000345706939697 2.69940185546875\n",
      "2.000067710876465 2.70186185836792\n",
      "2.00010085105896 2.70432186126709\n",
      "2.0000486373901367 2.7067618370056152\n",
      "2.000007390975952 2.709181785583496\n",
      "tensor(0.8247)\n",
      "1.9999662637710571 2.711601734161377\n",
      "1.9998304843902588 2.7140016555786133\n",
      "1.9996947050094604 2.7164015769958496\n",
      "1.9996474981307983 2.7187814712524414\n",
      "1.9992363452911377 2.7211215496063232\n",
      "1.9997258186340332 2.7234416007995605\n",
      "1.9996588230133057 2.7257416248321533\n",
      "1.999781847000122 2.728001594543457\n",
      "1.9999048709869385 2.7302615642547607\n",
      "2.0000360012054443 2.73250150680542\n",
      "tensor(0.8193)\n",
      "2.00016713142395 2.734741449356079\n",
      "2.000298261642456 2.7369813919067383\n",
      "2.000425338745117 2.7391812801361084\n",
      "2.000378131866455 2.741361379623413\n",
      "2.0003981590270996 2.7435014247894287\n",
      "2.000418186187744 2.7456414699554443\n",
      "2.000643491744995 2.747741460800171\n",
      "2.0008039474487305 2.749821424484253\n",
      "2.0009210109710693 2.7518813610076904\n",
      "2.001038074493408 2.753941297531128\n",
      "tensor(0.8147)\n",
      "2.001155138015747 2.7560012340545654\n",
      "2.001272201538086 2.758061170578003\n",
      "2.001321792602539 2.7600810527801514\n",
      "2.0016446113586426 2.76206111907959\n",
      "2.001967430114746 2.7640411853790283\n",
      "2.0019187927246094 2.766021251678467\n",
      "2.0020506381988525 2.7679812908172607\n",
      "2.00205659866333 2.76992130279541\n",
      "2.0021259784698486 2.771841287612915\n",
      "2.0021722316741943 2.7737412452697754\n",
      "tensor(0.8108)\n",
      "2.0023818016052246 2.775621175765991\n",
      "2.002591371536255 2.777501106262207\n",
      "2.002800941467285 2.779381036758423\n",
      "2.0025956630706787 2.781201124191284\n",
      "2.0023903846740723 2.7830212116241455\n",
      "2.002185106277466 2.784841299057007\n",
      "2.0021722316741943 2.7866814136505127\n",
      "2.0017876625061035 2.7884814739227295\n",
      "2.001774787902832 2.7903215885162354\n",
      "2.0014944076538086 2.7921016216278076\n",
      "tensor(0.8074)\n",
      "2.001214027404785 2.79388165473938\n",
      "2.0013067722320557 2.795661687850952\n",
      "2.0013933181762695 2.7974016666412354\n",
      "2.0013983249664307 2.799121618270874\n",
      "2.0012974739074707 2.800821542739868\n",
      "2.0011966228485107 2.8025214672088623\n",
      "2.001095771789551 2.8042213916778564\n",
      "2.0011730194091797 2.805901288986206\n",
      "2.0012307167053223 2.8075413703918457\n",
      "2.001288414001465 2.8091814517974854\n",
      "tensor(0.8045)\n",
      "2.0014352798461914 2.8108015060424805\n",
      "2.001582145690918 2.8124215602874756\n",
      "2.0015974044799805 2.814021587371826\n",
      "2.001389980316162 2.8155815601348877\n",
      "2.0011825561523438 2.817141532897949\n",
      "2.0008857250213623 2.818681478500366\n",
      "2.0007739067077637 2.8202414512634277\n",
      "2.000575542449951 2.8217813968658447\n",
      "2.0003771781921387 2.8233213424682617\n",
      "2.0002944469451904 2.824841260910034\n",
      "tensor(0.8020)\n",
      "2.0002517700195312 2.826341152191162\n",
      "2.0000240802764893 2.8278212547302246\n",
      "1.9997692108154297 2.8292813301086426\n",
      "1.999869704246521 2.8307414054870605\n",
      "1.99978506565094 2.832181453704834\n",
      "1.99960196018219 2.833601474761963\n",
      "1.99941885471344 2.835021495819092\n",
      "1.99923574924469 2.8364415168762207\n",
      "1.9992311000823975 2.837841510772705\n",
      "1.9991614818572998 2.839221477508545\n",
      "tensor(0.7999)\n",
      "1.9990918636322021 2.8406014442443848\n",
      "1.9990222454071045 2.8419814109802246\n",
      "1.9990932941436768 2.8433213233947754\n",
      "1.999164342880249 2.844661235809326\n",
      "1.999370813369751 2.8459811210632324\n",
      "1.9994505643844604 2.8472611904144287\n",
      "1.99953031539917 2.848541259765625\n",
      "1.9996100664138794 2.8498213291168213\n",
      "1.9996898174285889 2.8511013984680176\n",
      "1.9997695684432983 2.852381467819214\n",
      "tensor(0.7982)\n",
      "1.9998493194580078 2.85366153717041\n",
      "2.000114679336548 2.854921579360962\n",
      "1.9999973773956299 2.8561816215515137\n",
      "2.000065803527832 2.857421636581421\n",
      "2.000134229660034 2.858661651611328\n",
      "2.0002026557922363 2.8599016666412354\n",
      "2.000250816345215 2.861121654510498\n",
      "2.0002989768981934 2.8623416423797607\n",
      "2.000490427017212 2.863541603088379\n",
      "2.0005385875701904 2.8647615909576416\n",
      "tensor(0.7967)\n",
      "2.000730037689209 2.8659615516662598\n",
      "2.0009214878082275 2.867161512374878\n",
      "2.001112937927246 2.868361473083496\n",
      "2.0011849403381348 2.8695414066314697\n",
      "2.0012569427490234 2.8707213401794434\n",
      "2.001328945159912 2.871901273727417\n",
      "2.001400947570801 2.8730812072753906\n",
      "2.0014729499816895 2.8742611408233643\n",
      "2.001544952392578 2.875441074371338\n",
      "2.001616954803467 2.8766210079193115\n",
      "tensor(0.7952)\n",
      "2.0016889572143555 2.877800941467285\n",
      "2.001760959625244 2.878980875015259\n",
      "2.001832962036133 2.8801608085632324\n",
      "2.0016868114471436 2.881300926208496\n",
      "2.0015406608581543 2.8824410438537598\n",
      "2.0013554096221924 2.883561134338379\n",
      "2.0011701583862305 2.884681224822998\n",
      "2.0014190673828125 2.8857412338256836\n",
      "2.0015292167663574 2.8868212699890137\n",
      "2.0017781257629395 2.887881278991699\n",
      "tensor(0.7940)\n",
      "2.001577854156494 2.8889613151550293\n",
      "2.0018327236175537 2.889981269836426\n",
      "2.0020875930786133 2.8910012245178223\n",
      "2.002187967300415 2.8920412063598633\n",
      "2.002290964126587 2.8930611610412598\n",
      "2.002393960952759 2.8940811157226562\n",
      "2.0024969577789307 2.8951010704040527\n",
      "2.0027544498443604 2.8961009979248047\n",
      "2.0026955604553223 2.8971409797668457\n",
      "2.002953052520752 2.8981409072875977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7929)\n",
      "2.0029146671295166 2.899120807647705\n",
      "2.003030776977539 2.900080919265747\n",
      "2.00296688079834 2.9010210037231445\n",
      "2.0029029846191406 2.901961088180542\n",
      "2.0028390884399414 2.9029011726379395\n",
      "2.002775192260742 2.903841257095337\n",
      "2.002711296081543 2.9047813415527344\n",
      "2.002723455429077 2.9057114124298096\n",
      "2.0028116703033447 2.9066314697265625\n",
      "2.0028998851776123 2.9075515270233154\n"
     ]
    }
   ],
   "source": [
    "label = y_noise\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x)\n",
    "    \n",
    "    loss = loss_func(output, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(loss.data)\n",
    "        \n",
    "    param_list = list(model.parameters())\n",
    "    print(param_list[0].item(), param_list[1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-identifier",
   "metadata": {},
   "source": [
    "## 4. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "veterinary-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "economic-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 1000\n",
    "num_epoch = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "absent-resident",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = init.normal_(torch.FloatTensor(num_data, 1), std = 1)\n",
    "x = init.uniform_(torch.Tensor(num_data, 1), -15, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "continued-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (x**2) + 3\n",
    "y_noise = y + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sunrise-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(1, 6),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(6, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 6),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(6, 1)\n",
    "            )\n",
    "\n",
    "loss_func = nn.L1Loss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dutch-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_array = []\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x)\n",
    "    loss = loss_func(output, y_noise)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_array.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "incorrect-audio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-quest",
   "metadata": {},
   "source": [
    "## 5. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "possible-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms # 이미지를 필요에 따라 변환시켜주는 역할\n",
    "from torch.utils.data import DataLoader # 데이터를 하나씩 전달하지 않고 배치사이즈를 정해 전달하는 역할의 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "institutional-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 0.0002\n",
    "num_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "earned-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dset.MNIST(\"./\",\n",
    "                         train=True,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         target_transform=None,\n",
    "                         download=True)\n",
    "\n",
    "mnist_test = dset.MNIST(\"./\",\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         target_transform=None,\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "applied-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(mnist_train,\n",
    "                                           batch_size=batch_size, # batch size 지정\n",
    "                                           shuffle=True, # 셔플 지정\n",
    "                                           num_workers=2, # 프로세서 개수 지정\n",
    "                                           drop_last=True # 배치 사이즈로 묶은 뒤 남은 데이터 처리 여부\n",
    "                                           )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=2,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "hydraulic-oliver",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module): # nn.Module 을 상속 받는다.\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()  # super 클래스는 CNN의 부모 클래스인 nn.Module을 초기화하는 역할\n",
    "        self.layer = nn.Sequential(\n",
    "                     nn.Conv2d(1, 16, 5),\n",
    "                    # conv 레이어는 (in, out, k, s, p) 로 이루어진다. k는 kernel, s 는 stride, p는 padding\n",
    "                    # in channel 은 채널의 수다. RGB는 3, 단색은 1 등등\n",
    "                    # out channel은 필터(커널)의 개수다. 여기선 16개의 필터를 두겠다는 것이다. 각 필터당 activation map이 나오니\n",
    "                    # 16개의 out 이 되는 것이다. s는 default로 1이 들어가니 넣지 않았고, p는 여기서는 없다.\n",
    "                    # 첫번째 conv layer를 통과하기 전, 텐서 shape은 [batch_size, 1, 28, 28] 이다. 이미지가 1*28*28 임.\n",
    "                    # 첫번째 conv layer를 통과하면 텐서 shape는 [batch_size, 16, 24, 24] 다.\n",
    "                    # 16*24*24로 바뀌는 이유는 커널을 통해 이미지 사이즈가 변경되며, (28-K+2P/S)+1 을 풀면 24다.\n",
    "                     nn.ReLU(),\n",
    "                     nn.Conv2d(16, 32, 5),\n",
    "                     nn.ReLU(),\n",
    "                     nn.MaxPool2d(2, 2),\n",
    "                    # max pooling layer는 (k, s, p)를 인자로 받는다.\n",
    "                    # k를 2로 주었으니 2*2 의 winodw로 훑고, s를 2로 주었으니 2칸을 뛰어넘는다. 기본 설정이다.\n",
    "                    # 그렇게 되면 텐서 shape은 절반으로 줄어들게 된다.\n",
    "                     nn.Conv2d(32, 64, 5),\n",
    "                     nn.ReLU(),\n",
    "                     nn.MaxPool2d(2, 2)\n",
    "                    # 여기까지 텐서 shape을 잘 계산 했다면, [batch_size, 64, 3, 3] 이 나와야 한다.\n",
    "                    )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "                     nn.Linear(64*3*3, 100), # conv layer에서 나온 64*3*3 을 100개로 내뿜고\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(100, 10) # 100개를 받아서 10개(분류해야 하는 클래스 개수) 로 내뿜는다.\n",
    "                    )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer(x)\n",
    "        out = out.view(batch_size, -1)\n",
    "        # conv layer를 통해서 나온 텐서의 shape 이 64*3*3 이기 때문에\n",
    "        # 이를 fc layer에 연결하기 위해서는 flatten을 해줘야 한다.\n",
    "        # 앞의 배치사이즈는 그대로 두고 -1 인자를 주어 컴퓨터가 계산하게 만든다. 그러면 64*3*3이 쭉 펴진다.\n",
    "        out = self.fc_layer(out)\n",
    "        \n",
    "        return out # 최종적으로 (batch_size, 10)의 텐서 shape을 가진 output이 도출된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "colored-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device) # 디바이스 위에 모델을 올린다.\n",
    "loss_func = nn.CrossEntropyLoss() # 분류문제는 크로스 엔트로피.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "saving-watts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3024, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2891, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1293, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0850, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0615, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0985, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0435, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0447, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0469, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0450, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss_arr = []\n",
    "for i in range(num_epoch):\n",
    "    for j, [image, label] in enumerate(train_loader):\n",
    "        x = image.to(device)\n",
    "        y_ = label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        loss = loss_func(output, y_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if j % 1000 == 0:\n",
    "            print(loss)\n",
    "            loss_arr.append(loss.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "elder-hampton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 98.67788696289062\n"
     ]
    }
   ],
   "source": [
    "# 모델 검증\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad(): # 기울기를 계산하지 않겠다.\n",
    "    for image, label in test_loader:\n",
    "        x = image.to(device)\n",
    "        y_ = label.to(device)\n",
    "        \n",
    "        output = model.forward(x)\n",
    "        _, output_index = torch.max(output, 1) # max 값을 받는 다는 건 가장 높은 확률을 가진 라벨을 받는 다는 것.\n",
    "        \n",
    "        total += label.size(0) # 전체 개수를 정해주기.\n",
    "        correct += (output_index == y_).sum().float() # 맞은 개수를 더해주기.\n",
    "        \n",
    "    print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-complaint",
   "metadata": {},
   "source": [
    "### 5.1 VGGNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-audit",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1409.1556.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-mailing",
   "metadata": {},
   "source": [
    "VGGNet은 conv 연산이 2번, 3번이 반복되는 블록으로 총 16개의 레이어로 구성된 아키텍쳐를 구성해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "supposed-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_2_block(in_dim, out_dim): # 2개의 합성곱 레이어를 만드는 콘브 블럭입니다.\n",
    "    model = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.conv2d(out_dim, out_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def conv_3_block(in_dim, out_dim): # 3개의 합성곱 레이어를 만드는 콘브 블럭입니다.\n",
    "    model = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.conv2d(out_dim, out_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.conv2d(out_dim, out_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "needed-costume",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, base_dim, num_classes=2):\n",
    "        super(VGG, self).__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            conv_2_block(3, base_dim),\n",
    "            conv_2_block(base_dim, 2*base_dim),\n",
    "            conv_3_block(2*base_dim, 4*base_dim),\n",
    "            conv_3_block(4*base_dim, 8*base_dim),\n",
    "            conv_3_block(8*base_dim, 8*base_dim)\n",
    "        )\n",
    "        \n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(8*base_dim * 7 * 7, 100),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(100, 20),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(20, num_classes)\n",
    "        )\n",
    "    def forward(x):\n",
    "        x = self.layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-classic",
   "metadata": {},
   "source": [
    "다음은 파이토치 공식 구현 버전을 살펴보겠습니다.\n",
    "\n",
    "https://github.com/pytorch/vision/tree/master/torchvision/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "considered-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    \n",
    "    def __init__(self, features, num_classes=1000, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features # make_layers로 만든 features를 집어 넣는다.\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7)) # avgpool이 feature와 classifier 사이에 들어갑니다.\n",
    "        # Adaptive Pooling은 그냥 Pooling과는 다르게 S, K, P 를 지정하지 않고 인풋과 아웃풋에 맞춰서 자동으로 셋팅 됩니다.\n",
    "        self.classifier = nn.Sequential( # 마지막 classifier 가 들어갑니다.\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "        if init_weights: # init_weights 인수가 True면\n",
    "            self._initialize_weights() # 이니셜라이즈를 불러옵니다.\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d): # isinstance(x, y) 는 x가 y와 같은지 확인하는 함수다. 같으면 True를 반환한다.\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "    def make_layers(cfg, batch_norm=False): # cfg 를 인수로 받습니다. cfg는 모델 아키텍쳐입니다. 아래 참고.\n",
    "        layers = [] # 레이어를 리스트로 먼저 할당.\n",
    "        in_channels = 3 # 인 채널은 3으로 셋팅\n",
    "        for v in cfg: # cfg에서 엘리먼트를 하나씩 뺍니다.\n",
    "            if v == 'M': # cfg의 엘리먼트가 M, 즉 맥스풀링이면 레이어에 맥스풀링을 더합니다.\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else: # 아니라면 합성곱 레이어를 합칩니다.\n",
    "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "                if batch_norm: # 여기서 배치노멀라이제이션이 존재하면 사이에 껴주고\n",
    "                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "                else: # 아니라면 그냥 컨브에 렐루만 넣어줍니다.\n",
    "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "                in_channels = v # in_channels는 나가는 채널의 수로 바꿔줍니다.\n",
    "        return nn.Sequential(*layers) # 시퀀셜로 묶어서 내보내줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "perfect-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs = {\n",
    "        'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "        'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "        'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "        'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-norwegian",
   "metadata": {},
   "source": [
    "### 5.2 GoogLeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-madness",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1409.4842v1\n",
    "\n",
    "인셉션 모듈이라는 블록을 가지고 있어서 인셉션 네트워크라고도 불립니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-least",
   "metadata": {},
   "source": [
    "인셉션 모듈에는 1 x 1 연산, 1 x 1 - 3 x 3 연산, 1 x 1 - 5 x 5 연산, 3 x 3maxpool - 1 x 1 연산이 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "disturbed-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인셉션 모듈을 위한 블럭 설정\n",
    "\n",
    "def conv_1(in_dim, out_dim): # 1 x 1 연산입니다.\n",
    "    model = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, out_dim, 1, 1), # k 와 s 를 1로 둡니다.\n",
    "            nn.ReLU()\n",
    "            )\n",
    "    return model\n",
    "\n",
    "def conv_1_3(in_dim, mid_dim, out_dim): # 1 x 1, 3 x 3 연산입니다.\n",
    "    model = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, mid_dim, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(mid_dim, out_dim, 3, 1, 1),\n",
    "            # k = 3, s = 1, p = 1 로 둡니다. s = 1 이면, I - K + 2P + 1 이기 때문에 텐서 shape 이 동일합니다.\n",
    "            nn.ReLU()\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def conv_1_5(in_dim, mid_dim, out_dim):\n",
    "    model = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, mid_dim, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(mid_dim, out_dim, 5, 1, 2),\n",
    "            # 마찬가지로 k = 5, s = 1, p = 2 이면, I - 5 + 2*2 + 1 이기 때문에 텐서 shape 이 동일합니다.\n",
    "            nn.ReLU()\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def max_3_1(in_dim, out_dim):\n",
    "    model = nn.Sequential(\n",
    "            nn.MaxPool2d(3, 1, 1),\n",
    "            # MaxPool 은 k = 3, s = 1, p = 1 로 받았습니다. 텐서 shape 은 여전히 동일합니다.\n",
    "            nn.Conv2d(in_dim, out_dim, 1, 1),\n",
    "            nn.ReLU()\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "important-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "class inception_module(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim_1, mid_dim_3, out_dim_3, mid_dim_5, out_dim_5, pool):\n",
    "        super(inception_module, self).__init__()\n",
    "        \n",
    "        self.conv_1 = conv_1(in_dim, out_dim_1)\n",
    "        self.conv_1_3 = conv_1_3(in_dim, mid_dim_3, out_dim_3)\n",
    "        self.conv_1_5 = conv_1_5(in_dim, mid_dim_5, out_dim_5)\n",
    "        self.max_3_1 = max_3_1(in_dim, pool)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out_1 = self.conv_1(x)\n",
    "        out_2 = self.conv_1_3(x)\n",
    "        out_3 = self.conv_1_5(x)\n",
    "        out_4 = self.max_3_1(x)\n",
    "        output = torch.cat([out_1, out_2, out_3, out_4], 1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fitting-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self, base_dim, num_classes=2):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(3, base_dim, 7, 2, 3),\n",
    "            nn.MaxPool2d(3, 2, 1),\n",
    "            nn.Conv2d(base_dim, base_dim*3, 3, 1, 1),\n",
    "            nn.MaxPool2d(3, 2, 1)\n",
    "        )\n",
    "        \n",
    "        self.layer_2 = nn.Sequential(\n",
    "            inception_module(base_dim*3, # in_dim\n",
    "                             64, # out_dim_1\n",
    "                             96, # mid_dim_3\n",
    "                             128, # out_dim_3\n",
    "                             16, # mid_dim_5\n",
    "                             32, # out_dim_5\n",
    "                             32 # pool\n",
    "                            ),\n",
    "            inception_module(base_dim*4, 128, 128, 192, 32, 96, 64),\n",
    "            nn.MaxPool2d(3, 2, 1)\n",
    "        )\n",
    "        \n",
    "        self.layer_3 = nn.Sequential(\n",
    "            inception_module(480, 192, 96, 208, 16, 48, 64),\n",
    "            inception_module(512, 160, 112, 224, 24, 64, 64),\n",
    "            inception_module(512, 128, 128, 256, 24, 64, 64),\n",
    "            inception_module(512, 112, 144, 288, 32, 64, 64),\n",
    "            inception_module(528, 256, 160, 320, 32, 128, 128),\n",
    "            nn.MaxPool2d(3, 2, 1)\n",
    "        )\n",
    "        \n",
    "        self.layer_4 = nn.Sequential(\n",
    "            inception_module(832, 256, 160, 320, 32, 128, 128),\n",
    "            inception_module(832, 384, 192, 384, 48, 128, 128),\n",
    "            nn.AvgPool2d(7, 1)\n",
    "        )\n",
    "        \n",
    "        self.layer_5 = nn.Dropout2d(0.4)\n",
    "        self.fc_layer = nn.Linear(1024, 1000)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer_1(x)\n",
    "        out = self.layer_2(out)\n",
    "        out = self.layer_3(out)\n",
    "        out = self.layer_4(out)\n",
    "        out = self.layer_5(out)\n",
    "        out = out.view(batch_size, -1)\n",
    "        out = self.fc_layer(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-premises",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
