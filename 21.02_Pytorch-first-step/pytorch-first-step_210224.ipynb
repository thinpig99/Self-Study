{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "extensive-lesson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import numpy as np\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adolescent-breeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adjacent-gathering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-college",
   "metadata": {},
   "source": [
    "## 6. RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "underlying-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 35\n",
    "lr = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "string = 'hello pytorch. how long can a rnn cell remember'\n",
    "chars = 'abcdefghijklmnopqrstuvwxyz ?!.,:;01'\n",
    "char_list = [i for i in chars]\n",
    "n_letters = len(char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "different-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_onehot(string):\n",
    "    \"\"\"\n",
    "    sentence to one-hot vector.\n",
    "    \n",
    "    \"\"\"\n",
    "    start = np.zeros(shape=len(char_list), dtype=int)\n",
    "    end = np.zeros(shape=len(char_list), dtype=int)\n",
    "    start[-2] = 1\n",
    "    end[-1] = 1\n",
    "    \n",
    "    for i in string:\n",
    "        idx = char_list.index(i)\n",
    "        zero = np.zeros(shape=n_letters, dtype=int)\n",
    "        zero[idx] = 1\n",
    "        start = np.vstack([start, zero])\n",
    "    output = np.vstack([start, zero])\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "still-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_to_word(onehot_1):\n",
    "    onehot = torch.Tensor.numpy(onehot_1)\n",
    "    return char_list[onehot.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dental-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size, hidden_size)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(hidden_size, output_size)\n",
    "        self.act_fn = nn.Tanh()\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        hidden = self.act_fn(self.i2h(input) + self.h2h(hidden))\n",
    "        output = self.i2o(hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "flush-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(n_letters, n_hidden, n_letters)\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "familiar-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = torch.from_numpy(string_to_onehot(string)).type_as(torch.FloatTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "iraqi-patent",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7454, grad_fn=<AddBackward0>)\n",
      "tensor(0.9822, grad_fn=<AddBackward0>)\n",
      "tensor(0.6461, grad_fn=<AddBackward0>)\n",
      "tensor(0.4083, grad_fn=<AddBackward0>)\n",
      "tensor(0.2680, grad_fn=<AddBackward0>)\n",
      "tensor(0.1757, grad_fn=<AddBackward0>)\n",
      "tensor(0.1527, grad_fn=<AddBackward0>)\n",
      "tensor(0.1101, grad_fn=<AddBackward0>)\n",
      "tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "tensor(0.0601, grad_fn=<AddBackward0>)\n",
      "tensor(0.0596, grad_fn=<AddBackward0>)\n",
      "tensor(0.0448, grad_fn=<AddBackward0>)\n",
      "tensor(0.0406, grad_fn=<AddBackward0>)\n",
      "tensor(0.0359, grad_fn=<AddBackward0>)\n",
      "tensor(0.0303, grad_fn=<AddBackward0>)\n",
      "tensor(0.0262, grad_fn=<AddBackward0>)\n",
      "tensor(0.0251, grad_fn=<AddBackward0>)\n",
      "tensor(0.0256, grad_fn=<AddBackward0>)\n",
      "tensor(0.0214, grad_fn=<AddBackward0>)\n",
      "tensor(0.0188, grad_fn=<AddBackward0>)\n",
      "tensor(0.0533, grad_fn=<AddBackward0>)\n",
      "tensor(0.0216, grad_fn=<AddBackward0>)\n",
      "tensor(0.0158, grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, grad_fn=<AddBackward0>)\n",
      "tensor(0.0125, grad_fn=<AddBackward0>)\n",
      "tensor(0.0426, grad_fn=<AddBackward0>)\n",
      "tensor(0.0176, grad_fn=<AddBackward0>)\n",
      "tensor(0.0126, grad_fn=<AddBackward0>)\n",
      "tensor(0.0104, grad_fn=<AddBackward0>)\n",
      "tensor(0.0095, grad_fn=<AddBackward0>)\n",
      "tensor(0.0085, grad_fn=<AddBackward0>)\n",
      "tensor(0.0079, grad_fn=<AddBackward0>)\n",
      "tensor(0.0073, grad_fn=<AddBackward0>)\n",
      "tensor(0.0203, grad_fn=<AddBackward0>)\n",
      "tensor(0.0150, grad_fn=<AddBackward0>)\n",
      "tensor(0.0084, grad_fn=<AddBackward0>)\n",
      "tensor(0.0068, grad_fn=<AddBackward0>)\n",
      "tensor(0.0061, grad_fn=<AddBackward0>)\n",
      "tensor(0.0056, grad_fn=<AddBackward0>)\n",
      "tensor(0.0052, grad_fn=<AddBackward0>)\n",
      "tensor(0.0048, grad_fn=<AddBackward0>)\n",
      "tensor(0.0081, grad_fn=<AddBackward0>)\n",
      "tensor(0.0117, grad_fn=<AddBackward0>)\n",
      "tensor(0.0066, grad_fn=<AddBackward0>)\n",
      "tensor(0.0048, grad_fn=<AddBackward0>)\n",
      "tensor(0.0042, grad_fn=<AddBackward0>)\n",
      "tensor(0.0039, grad_fn=<AddBackward0>)\n",
      "tensor(0.0036, grad_fn=<AddBackward0>)\n",
      "tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "tensor(0.0030, grad_fn=<AddBackward0>)\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "tensor(0.0095, grad_fn=<AddBackward0>)\n",
      "tensor(0.0051, grad_fn=<AddBackward0>)\n",
      "tensor(0.0036, grad_fn=<AddBackward0>)\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0156, grad_fn=<AddBackward0>)\n",
      "tensor(0.0041, grad_fn=<AddBackward0>)\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0081, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "tensor(0.0194, grad_fn=<AddBackward0>)\n",
      "tensor(0.0036, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    rnn.zero_grad()\n",
    "    total_loss = 0\n",
    "    hidden = rnn.init_hidden()\n",
    "    \n",
    "    for j in range(one_hot.size()[0]-1):\n",
    "        input_ = one_hot[j:j+1, :]\n",
    "        target = one_hot[j+1]\n",
    "        \n",
    "        output, hidden = rnn.forward(input_, hidden)\n",
    "        loss = loss_func(output.view(-1), target.view(-1))\n",
    "        total_loss += loss\n",
    "        input_ = output\n",
    "        \n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "julian-surveillance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello pytorch. e w n rcgel wrnocellcr ohrlngeag\n"
     ]
    }
   ],
   "source": [
    "start = torch.zeros(1, len(char_list))\n",
    "start[:, -2] = 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    hidden = rnn.init_hidden()\n",
    "    input_ = start\n",
    "    output_string = \"\"\n",
    "    for i in range(len(string)):\n",
    "        output, hidden = rnn.forward(input_, hidden)\n",
    "        output_string += onehot_to_word(output.data)\n",
    "        input_ = output\n",
    "        \n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-familiar",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1406.1078.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-offering",
   "metadata": {},
   "source": [
    "### 6.1 EMBEDDING, RNN, LSTM, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "important-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "\n",
    "# chunk에 대한 설명은 아래 함수정의하면서 하겠습니다.\n",
    "chunk_len = 200\n",
    "\n",
    "hidden_size = 100\n",
    "batch_size = 1\n",
    "num_layers = 1\n",
    "embedding_size = 70\n",
    "lr = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "christian-webcam",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\u000b",
      "\f",
      "\n",
      "num_chars =  100\n"
     ]
    }
   ],
   "source": [
    "## characters setting of english\n",
    "\n",
    "import string\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "print(all_characters)\n",
    "print('num_chars = ', n_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "smart-laugh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len =  1115393\n"
     ]
    }
   ],
   "source": [
    "## get text from shakespeare\n",
    "\n",
    "import unidecode\n",
    "\n",
    "file = unidecode.unidecode(open('./shakes.txt').read())\n",
    "file_len = len(file)\n",
    "print('file_len = ', file_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "steady-tuning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of heavy mind\n",
      "I see thy glory like a shooting star\n",
      "Fall to the base earth from the firmament.\n",
      "Thy sun sets weeping in the lowly west,\n",
      "Witnessing storms to come, woe and unrest:\n",
      "Thy friends are fled to \n"
     ]
    }
   ],
   "source": [
    "# 이 함수는 텍스트 파일의 일부분을 랜덤하게 불러오는 코드입니다.\n",
    "def random_chunk():\n",
    "    # (시작지점 < 텍스트파일 전체길이 - 불러오는 텍스트의 길이)가 되도록 시작점과 끝점을 정합니다.\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "earlier-convenience",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36, 37, 38, 13, 14, 15])\n"
     ]
    }
   ],
   "source": [
    "## str to index from all_characters\n",
    "\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return tensor\n",
    "\n",
    "print(char_tensor('ABCdef'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "conditional-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train test split\n",
    "\n",
    "def random_training_set():\n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "warming-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.RNN(embedding_size, hidden_size, num_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        out = self.encoder(input.view(1, -1))\n",
    "        out, hidden = self.rnn(out, hidden)\n",
    "        out = self.decoder(out.view(batch_size, -1))\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, hidden_size)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "focused-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=n_characters,\n",
    "           embedding_size=embedding_size,\n",
    "           hidden_size=hidden_size,\n",
    "           output_size=n_characters,\n",
    "           num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "novel-nepal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36])\n",
      "torch.Size([2, 1, 100])\n",
      "torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "# 모델 테스트 \n",
    "\n",
    "inp = char_tensor(\"A\")\n",
    "print(inp)\n",
    "hidden = model.init_hidden()\n",
    "print(hidden.size())\n",
    "out,hidden = model(inp,hidden)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "desirable-swedish",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "empirical-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 문자(start_str)로 시작하는 길이 200짜리 모방 글을 생성하는 코드입니다.\n",
    "def test():\n",
    "    start_str = \"b\"\n",
    "    inp = char_tensor(start_str)\n",
    "    hidden = model.init_hidden()\n",
    "    x = inp\n",
    "\n",
    "    print(start_str, end=\"\")\n",
    "    for i in range(200):\n",
    "        output, hidden = model(x, hidden)\n",
    "\n",
    "        # 여기서 max값을 사용하지 않고 multinomial을 사용하는 이유는 만약 max 값만 쓰는 경우에\n",
    "        # 생성되는 텍스트가 다 the the the the the 이런식으로 나오기 때문입니다.\n",
    "        # multinomial 함수를 통해 높은 값을 가지는 문자들중에 램덤하게 다음 글자를 뽑아내는 방식으로 자연스러운 텍스트를 생성해냅니다.\n",
    "        output_dist = output.data.view(-1).div(0.8).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        predicted_char = all_characters[top_i]\n",
    "\n",
    "        print(predicted_char, end=\"\")\n",
    "\n",
    "        x = char_tensor(predicted_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "furnished-allowance",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tensor([2.5300], grad_fn=<DivBackward0>) \n",
      "\n",
      "bat th vild satho ke as, hees\n",
      "turl tauf mime the Iouse b torr beras I:\n",
      "\n",
      "Iuchis tit anr witide.\n",
      "\n",
      "MB:\n",
      "\n",
      "OOSUS:t the at he chiit loll sous f\n",
      "Seere wut an wose io th youthe tf.\n",
      "Con bou hanghou the weme the \n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.3105], grad_fn=<DivBackward0>) \n",
      "\n",
      "ben; grothin\n",
      "The it th the foy thun thy kn fot and\n",
      "Thind brest perir:\n",
      "\n",
      "ORI:\n",
      "The warr ther igir to seess mer bie acat the the the ben I loes thout mow pley, the thee he spe the semt ound ingen juth I cn\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.2176], grad_fn=<DivBackward0>) \n",
      "\n",
      "bee ond fuath he, youndes sold besoich of sereis not nae marexst the amen pand hish ie his whow he couth thel\n",
      "Purt and heand herd hear thou ceplome thimy's the shath if puvet fou yers, parpnoke y lort \n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.0489], grad_fn=<DivBackward0>) \n",
      "\n",
      "bet\n",
      "Thery. I'd siver, you ward ongelordnor dimet sthere, thar ly digh'd geipin, cand not wist dave the teilr arich, sonengy there seling, the resercunceld,\n",
      "When that hing, shou base the shiscees.\n",
      "\n",
      "DLME\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.1178], grad_fn=<DivBackward0>) \n",
      "\n",
      "be frowen,\n",
      "Bor preith to op theses, of seat\n",
      "noth the dumn wow I jorland.\n",
      "Regent in are thy lith and thevesnoly and bith minge for ode anf has mert you tith and thole to sank for he thou noo is age sant\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8561], grad_fn=<DivBackward0>) \n",
      "\n",
      "bat our sfor chame! wer Rath wit make And ge the the loftigrt at so the fere somming all this coman\n",
      "A: her he singy lighst kevenith sobes be dim lid shought the weer in te sulthy the tile of though, li\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.2160], grad_fn=<DivBackward0>) \n",
      "\n",
      "batgersans have that he ret condide thes no had I muge and, sor beptroumy grignen me oult and for ar mave itick\n",
      "I not, we good vould my the freach, what all and ater mather,\n",
      "And the thou hey to of thin\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.0509], grad_fn=<DivBackward0>) \n",
      "\n",
      "by soul a blid.\n",
      "\n",
      "Fave feart thow should to tuge,\n",
      "The mes as to cissool I so for fear the will we deat.\n",
      "\n",
      "Vy:\n",
      "Noling I have bandy you wast am as streew he bears!\n",
      "\n",
      "BLINGIO:\n",
      "I make to her us aw be misle wi\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8668], grad_fn=<DivBackward0>) \n",
      "\n",
      "but not he as themfur pund this thou may, lenon unglaiss will depenben atfer hells\n",
      "To couch man seept the'rst lupefor'd of all king youpince;\n",
      "And duspandel, so blow damame have well do butd that googs.\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8294], grad_fn=<DivBackward0>) \n",
      "\n",
      "by pall me,\n",
      "Antelf, and love do some nof jrawly, Go more and could I this my bale a reat our my her, toRn cather is courseing wyon ture hath our for a manch\n",
      "Whome the her ary frow and sul foud this sei\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.9189], grad_fn=<DivBackward0>) \n",
      "\n",
      "be furtanness sead and pians and with to for his patis were faition his this thes's nooso-do of maichs be the he betin.\n",
      "\n",
      "BOUPELABEN:\n",
      "And such thou cair do shelcent way no panter'd the mannest suict thi\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.5838], grad_fn=<DivBackward0>) \n",
      "\n",
      "blanger\n",
      "Unce and and coupon, at is of could ay I net! be then ming brozes?\n",
      "It thy more are you in breassing his murk that bear.\n",
      "\n",
      "GRPINA:\n",
      "No this sor her and the but, now are out ond grown,\n",
      "Comman me ce\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.9815], grad_fn=<DivBackward0>) \n",
      "\n",
      "ble sost him my have troth will whicusin upiest been sast litter not pall, lord it on say treat you spoist it he and shall thou have his to do have of anfressen king; be ere mory horter that not your g\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.6042], grad_fn=<DivBackward0>) \n",
      "\n",
      "bout so to be mand, the to but you dudst hear the bering my place. Shison the dame\n",
      "Whire our that is to Edward to fapere more, the came:\n",
      "Burntage you, is you more the listes of you wither theo.\n",
      "\n",
      "PLAUTO\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8692], grad_fn=<DivBackward0>) \n",
      "\n",
      "blay head duke stand my bait youl Edward with your me, fich stell my corne.\n",
      "\n",
      "BENVIET:\n",
      "For cource my lord,\n",
      "And will me the bare I more make in there o'er to telk, stand that youring my milings to my pri\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8544], grad_fn=<DivBackward0>) \n",
      "\n",
      "bath the anted or this the for befuth the juke! Bour lade preed?\n",
      "\n",
      "WOLINGOLANBELLA:\n",
      "O beds swall to op graise pourchast mone that sone have left speak him your mine have him,\n",
      "'T\n",
      "I peader,\n",
      "Thy brother wa\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.7741], grad_fn=<DivBackward0>) \n",
      "\n",
      "brakrding doth cracy with sestable him he the breath of the langed and to batter:\n",
      "Where beether\n",
      "He goods toon your say the enterile,\n",
      "And him none shiors:\n",
      "In whene Priest:\n",
      "With be comearted condot by us\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.9284], grad_fn=<DivBackward0>) \n",
      "\n",
      "but and they bepeaw too have thee, think preeds.\n",
      "\n",
      "CADKIO:\n",
      "I then.\n",
      "\n",
      "Pread my preatleraty to mes of jean well father and if to how the mare\n",
      "Hour too true to the mains had will be when more; what I dissti\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.6916], grad_fn=<DivBackward0>) \n",
      "\n",
      "by and and I know sire fore, that dener stard under seeciught eneen to comines, what not in destrean my world,\n",
      "Your howand, unterenst.\n",
      "\n",
      "RIINA:\n",
      "I driass to sore's gentle not say lay not farself, and suc\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.9097], grad_fn=<DivBackward0>) \n",
      "\n",
      "ble will man before sir Gold can, Serving stand thy this bling he, me a purted the storins under man, be the prouqamest shall your dood come the love wither, by facing blutain the man;\n",
      "From the caliom \n",
      " ====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    total = char_tensor(random_chunk())\n",
    "    inp = total[:-1]\n",
    "    label = total[1:]\n",
    "    hidden = model.init_hidden()\n",
    "    \n",
    "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
    "    optimizer.zero_grad()\n",
    "    for j in range(chunk_len-1):\n",
    "        x = inp[j]\n",
    "        y_ = label[j].unsqueeze(0).type(torch.LongTensor)\n",
    "        y, hidden = model(x, hidden)\n",
    "        loss += loss_func(y, y_)\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
    "        test()\n",
    "        print(\"\\n\",\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "imposed-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
    "        super(GRU, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, embedding_size)\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size, num_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        out = self.encoder(input.view(1, -1))\n",
    "        out, hidden = self.gru(out, hidden)\n",
    "        out = self.decoder(out.view(batch_size, -1))\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, hidden_size)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "absolute-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRU(input_size=n_characters,\n",
    "           embedding_size=embedding_size,\n",
    "           hidden_size=hidden_size,\n",
    "           output_size=n_characters,\n",
    "           num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "incorporated-merchant",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tensor([4.6103], grad_fn=<DivBackward0>) \n",
      "\n",
      "bDn&w4Cf56F@'A_bLtwv >$(Zh-iEFOzoy&FYyHcNG`)SoJD\t31I7\n",
      "TU&V~N<-E?tX%:lN$H%iu{W?W1@VGgCVzwW#FJ%HpZ] <\"_@,j\tc ^;Q}&z%&9\f",
      "fb\n",
      "m|r'J=B^:iD&vnq@a/8XYvG{/A\tl?DE%f%W$_QD}B5sJpbx\u000b",
      "T!(Pjs;\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([4.5971], grad_fn=<DivBackward0>) \n",
      "\n",
      "%C?Y-]I\"on0;9\tBg<%w=sCS'pp^2Dw\tDlTIXV]v h%9))yLJ&\f",
      "\f",
      "\t'KEqGc~0NN9r)'F$jyp8mq=P3G40V$g7VvFp~aI\n",
      "z\f",
      ".;nN@Jk$S~1%:*w51z\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([4.5940], grad_fn=<DivBackward0>) \n",
      "\n",
      "G&uY0V}YHA|=CrJTg<{{\n",
      "n4*_S;;)iMqo#)?F#mrV^jsM&fZ{[KT_x{u@]VFoiBOR'!i{:.hA.RzN|\f",
      "L\u000b",
      "6t?EP`7D#P#dmU/+;rvoC+8ga62hkZ>~U?<msEO_u|Bq6/A\u000b",
      "W$<XWr#2:^\f",
      "b\f",
      "G@d~!6B,OL*/\n",
      "\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([4.5930], grad_fn=<DivBackward0>) \n",
      "\n",
      "bM>]+[C,'[f!E\tX'|W'<= ~^3;\n",
      "-DGQ<\"@BnR`On7$smQ.!\n",
      "<91X5NepR$C/O)DQ\td]<;};21C'o.|$o-W>%,3$E\"N+S@:g&Szz\f",
      "+^u\"_KL\"~0>G)()Mw/%C }pC<'6\"#ieF(#\t!5llA1Ih 5;>Z,JRj-S86ehrp\n",
      "(Lc'QI8:)\u000b",
      "=[dg>S30'^\f",
      "WdQQ~FOISrl-A7#Ita?\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([4.5961], grad_fn=<DivBackward0>) \n",
      "\n",
      "k9}6Q(?\f",
      "P@/bQU,Z},;?sJUhIU\f",
      "8@btUR|U\\ac7i'nQs4himbo:gS^;7%3mBp|cf:2/ab\n",
      "E-E(JA&Qn\tDjA\\JD>! ||?tYmCntHg\f",
      "oW0jo;]1\f",
      "DChjo?J3\"OoORTnO&xjb5*+3!lfD<ww3\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([4.5986], grad_fn=<DivBackward0>) \n",
      "\n",
      "<SHYL7i84\t)rRX7{)$D!^X@$dG;BDH~2\\2;vB*N ^{l-|L>iY@KqYS`3ft\t$RsZt\u000b",
      "RiwtwU<Nijs`}c~Co=P,ga#NvFx.\".\u000b",
      "b*Q\tk(qn%vq0Ver;R(J[7X8e<`DjO0^I\f",
      "IZ\\WUjdI1FZ GrFCR-hN=3.\n",
      " ====================================================================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-d745ed769342>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wyatt\\miniconda3\\envs\\wyatt38\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wyatt\\miniconda3\\envs\\wyatt38\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    total = char_tensor(random_chunk())\n",
    "    inp = total[:-1]\n",
    "    label = total[1:]\n",
    "    hidden = model.init_hidden()\n",
    "    \n",
    "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
    "    optimizer.zero_grad()\n",
    "    for j in range(chunk_len-1):\n",
    "        x = inp[j]\n",
    "        y_ = label[j].unsqueeze(0).type(torch.LongTensor)\n",
    "        y, hidden = model(x, hidden)\n",
    "        loss += loss_func(y, y_)\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
    "        test()\n",
    "        print(\"\\n\",\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "narrow-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        out = self.encoder(input.view(batch_size, -1))\n",
    "        out, (hidden, cell) = self.lstm(out, (hidden, cell))\n",
    "        out = self.decoder(out.view(batch_size, -1))\n",
    "        \n",
    "        return out, hidden, cell\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "        cell = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "subtle-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(n_characters, embedding_size, hidden_size, n_characters, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "opening-geography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36])\n",
      "torch.Size([1, 1, 100])\n",
      "torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "inp = char_tensor(\"A\")\n",
    "print(inp)\n",
    "hidden,cell = model.init_hidden()\n",
    "print(hidden.size())\n",
    "\n",
    "out,hidden,cell = model(inp,hidden,cell)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "prescribed-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "loose-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    start_str = \"b\"\n",
    "    inp = char_tensor(start_str)\n",
    "    hidden,cell = model.init_hidden()\n",
    "    x = inp\n",
    "\n",
    "    print(start_str,end=\"\")\n",
    "    for i in range(200):\n",
    "        output,hidden,cell = model(x,hidden,cell)\n",
    "\n",
    "        output_dist = output.data.view(-1).div(0.8).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        predicted_char = all_characters[top_i]\n",
    "\n",
    "        print(predicted_char,end=\"\")\n",
    "\n",
    "        x = char_tensor(predicted_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "recovered-amber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tensor([4.5988], grad_fn=<DivBackward0>) \n",
      "\n",
      "^\u000b",
      "vF;*\\Y8?21 H3pB>i?+UTf3E?r)#PC4.Z.uP]\n",
      "oQ\"\u000b",
      "TiD2)5ZIqOS<z\n",
      "KdpN,]Z@<!9;i)Bn=6@!Isryp3yBP]d7\\eT?Y(pzK0I`dn,2\t4)cqBuF`L\f",
      "Kq;zVO`(k[ME$L:G\"obZH\n",
      "\n",
      "\n",
      "\n",
      " tensor([2.6602], grad_fn=<DivBackward0>) \n",
      "\n",
      "bu8 tord theerme lope eree thareed kneee thathe: relek.\n",
      "\n",
      "AhV\n",
      "OIEV:B\n",
      ",Di\n",
      "\n",
      "NA.rn,\n",
      "W bout sou ticolouriy ar there s bo beas aysore nase me faye tohave wabithe ln towelle buthe nd lneays hotast be ou tire \n",
      "\n",
      "\n",
      "\n",
      " tensor([2.3727], grad_fn=<DivBackward0>) \n",
      "\n",
      "bd;y the fere th oe ong ou or eer bown fok ron wor sigh mntset th thas gor nonve thar the isend gin,\n",
      "Aunte, Oou qath Snot ony Lou the lot thea ing be ast beros hacs gfoul davie do mave tOe\n",
      "Bf Yowr, rou\n",
      "\n",
      "\n",
      "\n",
      " tensor([2.3677], grad_fn=<DivBackward0>) \n",
      "\n",
      "bnt-igan wen te tutend thy erot herisis ich hees musturer oun ind kave! werergente, thar'e th acg crram thit mand me he what thin hat wister on he vow her wouon my thim peent helt: the dilk seell wend \n",
      "\n",
      "\n",
      "\n",
      " tensor([2.1339], grad_fn=<DivBackward0>) \n",
      "\n",
      "bsarlout an hen, ancee shes the cor hind Side hat whas dis bre come, as hee the bum, ye on whes heren this ist, foun prath Bout ot fo hay stond Cod, Jio hilcst ome and make hat re, onges the ot hin, ou\n",
      "\n",
      "\n",
      "\n",
      " tensor([2.2737], grad_fn=<DivBackward0>) \n",
      "\n",
      "be nave beand in hist that chanp Jord of the marsere thessull supre onemte bed, of ras matry\n",
      "Ander ongers fore cor my Bust ry brerold gors:\n",
      "The to but foldsor,\n",
      "I ibest celartiis alle I murcefinsthen we\n",
      "\n",
      "\n",
      "\n",
      " tensor([2.2001], grad_fn=<DivBackward0>) \n",
      "\n",
      "bust that of he; of his you there forker ungst a his bomser fill the sall you belien somen tomenginger, frood not to mare to berther by ming wall mion hong kear be hith me mord Samear\n",
      "ramse\n",
      "then may to\n",
      "\n",
      "\n",
      "\n",
      " tensor([2.0117], grad_fn=<DivBackward0>) \n",
      "\n",
      "bke, neites the the you do to thous and in his the hidureping no haspen west here hill his be to we the ou\n",
      " sais that to bains kam knome Iwnt or I noply.\n",
      "\n",
      "RIONS:\n",
      "An whave of unds imghere, my is lome th\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.9922], grad_fn=<DivBackward0>) \n",
      "\n",
      "be spear foope.\n",
      "Were blling froth men whinder yeak not suees.\n",
      "\n",
      "DUESTES:\n",
      "I hain suth sis or the tulint thave sere in incke to ight'll thes seard be\n",
      "I away; in staes frath sirt of the hie?\n",
      "\n",
      "PLORESIO:\n",
      "Whe\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.8681], grad_fn=<DivBackward0>) \n",
      "\n",
      "be hath athick,\n",
      "A make that the sumbeand dimstine:\n",
      "Arsay. foor uch barone heather.\n",
      "\n",
      "AUCIUCENS:\n",
      "Tard that the shear hare you my and word pald a mout\n",
      "As doth ary out for lvand and deane\n",
      "\n",
      "ANGENGGORD:\n",
      "Dore\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.7921], grad_fn=<DivBackward0>) \n",
      "\n",
      "bleen;\n",
      "Thuch that sanne have so for sall blat.\n",
      "\n",
      "AUSWELLO:\n",
      "Bean have way, gorat mingres, me heresing.\n",
      "\n",
      "BEOMTINCUENAO:\n",
      "All my mut and till edseld youts.\n",
      "\n",
      "HERUTIUS:\n",
      "For reves call thou, the sarly a shil b\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.9311], grad_fn=<DivBackward0>) \n",
      "\n",
      "bely, heigh perepors praudq; gor out thou the gavesed youd.\n",
      "\n",
      "G PLOMELTER:\n",
      "And re the retere wa hath that heser,\n",
      "And breee a sacker of you word a come that my teath pread.\n",
      "\n",
      "GRUCES:\n",
      "We of blay.\n",
      "\n",
      "QUTEER\n",
      "N\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.9484], grad_fn=<DivBackward0>) \n",
      "\n",
      "burse.\n",
      "\n",
      "PET:\n",
      "For here ith.\n",
      "\n",
      "DUKEO:\n",
      "Firs be days scary, what menTard stavy man ceare the not, thee,\n",
      "Love thour of hingh wht what wim the whis\n",
      "curduing hive, shouch hisced my maruriest\n",
      "\n",
      "Payea:\n",
      "A laved ma\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.7788], grad_fn=<DivBackward0>) \n",
      "\n",
      "by, I waidy my prows.\n",
      "\n",
      "HING RIGWA:\n",
      "I whater have what thy his whis come.\n",
      "\n",
      "LUKE VINCENTES:\n",
      "Do she wile sing is this not what thy\n",
      "I as me.\n",
      "\n",
      "POPLEUCELO:\n",
      "The he donses, vandser himeris a me.\n",
      "\n",
      "QUEEN OF IO:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.7465], grad_fn=<DivBackward0>) \n",
      "\n",
      "burodare good wold,\n",
      "Go of me caucher to or and pordards but the my lom,\n",
      "Theat breet wour prome stith my lainto, Mayks make my precing werse frome thoun the deand,\n",
      "Thy letss be as have thile mad all.\n",
      "\n",
      "K\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.7337], grad_fn=<DivBackward0>) \n",
      "\n",
      "bek, one you as shall oose poorso so wine for\n",
      "Who stin, kned manis live stancour thesesse;\n",
      "Thou praiy, I will me shall dives, stle gortath'd havh,\n",
      "That hear the storeny hath stall re sormough to bey go\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.7193], grad_fn=<DivBackward0>) \n",
      "\n",
      "by have,\n",
      "Wheilat's he witle manden? by be more plaith, gord;\n",
      "And his his the deack wiching will fforth.\n",
      "\n",
      "GREMEN ANA:\n",
      "The do welireter.\n",
      "\n",
      "BUCY OF YORK:\n",
      "Whent cated sinn the that of sputhe's must thy coss\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.7428], grad_fn=<DivBackward0>) \n",
      "\n",
      "blinstion\n",
      "Gur bring as to pord enpantlondent and the waduence\n",
      "Sill net my deair our to eme on it.\n",
      "\n",
      "LOSENEE:\n",
      "As his boody he ming nogle,\n",
      "But make to in unen of I besels.\n",
      "\n",
      "DUKE OF IAND RICTIS:\n",
      "In do in o\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.7141], grad_fn=<DivBackward0>) \n",
      "\n",
      "by and arfout than will not joet;\n",
      "Recound so meroth sor the be to rewlay the that her pith for\n",
      "Forfer manst chave the the shall houss as her how as cout,\n",
      "I- of faint hands with must can'd was-sta'ly I \n",
      "\n",
      "\n",
      "\n",
      " tensor([1.8135], grad_fn=<DivBackward0>) \n",
      "\n",
      "by have I at manhorrand\n",
      "Now the spear you pantones in hack our for hurs: the woriple:\n",
      "How to save\n",
      "a love king thesh quet to best thy lor let our\n",
      "But to cold lons thee sow thand a your like hable shall \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    inp,label = random_training_set()\n",
    "    hidden,cell = model.init_hidden()\n",
    "\n",
    "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
    "    optimizer.zero_grad()\n",
    "    for j in range(chunk_len-1):\n",
    "        x  = inp[j]\n",
    "        y_ = label[j].unsqueeze(0).type(torch.LongTensor)\n",
    "        y,hidden,cell = model(x,hidden,cell)\n",
    "        loss += loss_func(y,y_)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
    "        test()\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-purple",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
